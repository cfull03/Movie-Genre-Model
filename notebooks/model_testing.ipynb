{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "131c1419",
      "metadata": {},
      "source": [
        "# Model Testing and Comparison Notebook\n",
        "\n",
        "This notebook provides a framework for testing and comparing different machine learning models for movie genre classification.\n",
        "\n",
        "## Features:\n",
        "- Easy model configuration and testing\n",
        "- Automatic metric calculation and comparison\n",
        "- Visualization of results\n",
        "- Support for multiple model types (Logistic Regression, XGBoost, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1b21c6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-14 12:32:51.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/christianfullerton/Developer/Python Workspace/movie_genre_model\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ XGBoost available\n",
            "✓ All imports successful\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, \n",
        "    hamming_loss, jaccard_score, confusion_matrix\n",
        ")\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import json\n",
        "\n",
        "# Try importing XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "    print(\"✓ XGBoost available\")\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"⚠ XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "# Project imports\n",
        "from descriptions.config import INTERIM_DATA_DIR, MODELS_DIR\n",
        "from descriptions.dataset import load_interim\n",
        "from descriptions.modeling.train import prepare_features_and_labels\n",
        "from descriptions.modeling.preprocess import load_preprocessors\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"✓ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0248b936",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c2febb7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "\u001b[32m2025-12-14 12:32:53.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoading interim data from /Users/christianfullerton/Developer/Python Workspace/movie_genre_model/data/interim/cleaned_movies.csv...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:32:53.510\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mLoaded with index column\u001b[0m\n",
            "\u001b[32m2025-12-14 12:32:53.510\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m108\u001b[0m - \u001b[32m\u001b[1m✓ Data loaded successfully: 9087 rows, 2 columns\u001b[0m\n",
            "✓ Loaded 9087 samples\n",
            "Columns: ['genre', 'description']\n",
            "\n",
            "First few rows:\n",
            "                                     genre  \\\n",
            "movie_name                                   \n",
            "he_hawshank_edemption         Drama, Crime   \n",
            "he_odfather                   Drama, Crime   \n",
            "he_odfather_art_              Drama, Crime   \n",
            "chindlers_ist          Drama, History, War   \n",
            "12_ngry_en                           Drama   \n",
            "\n",
            "                                                             description  \n",
            "movie_name                                                                \n",
            "he_hawshank_edemption  Imprisoned in the 1940s for the double murder ...  \n",
            "he_odfather            Spanning the years 1945 to 1955, a chronicle o...  \n",
            "he_odfather_art_       In the continuing saga of the Corleone crime f...  \n",
            "chindlers_ist          The true story of how businessman Oskar Schind...  \n",
            "12_ngry_en             The defense and the prosecution have rested an...  \n",
            "\n",
            "Splitting data...\n",
            "✓ Data split complete\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data\n",
        "print(\"Loading data...\")\n",
        "data = load_interim(INTERIM_DATA_DIR / \"cleaned_movies.csv\")\n",
        "print(f\"✓ Loaded {len(data)} samples\")\n",
        "print(f\"Columns: {list(data.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Split data into train and test sets BEFORE preprocessing (prevents data leakage)\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "X, y = data['description'], data['genre']\n",
        "\n",
        "print(\"\\nSplitting data...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "print(\"✓ Data split complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "329da199",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing genres...\n",
            "Sample y_train: ['Horror', 'Mystery']\n",
            "Sample y_test: ['Adventure', 'Science Fiction', 'Western']\n",
            "\n",
            "Transforming text to TF-IDF features...\n",
            "✓ TF-IDF features: 10000 features\n",
            "\n",
            "Transforming genres to binary labels...\n",
            "✓ Binary labels: 18 genres\n",
            "✓ Training labels shape: (7269, 18)\n",
            "✓ Test labels shape: (1818, 18)\n",
            "✓ KBest selected 4500 features\n",
            "✓ Training features shape: (7269, 4500)\n",
            "✓ Test features shape: (1818, 4500)\n",
            "✓ SVD reduced to 2000 features\n",
            "✓ Training features shape: (7269, 2000)\n",
            "✓ Test features shape: (1818, 2000)\n"
          ]
        }
      ],
      "source": [
        "# Preprocess data: TF-IDF features and multi-label encoding\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Convert genre strings to lists of genre strings\n",
        "def preprocess_genres(genre_series):\n",
        "    \"\"\"Convert genre strings to lists of genre strings.\"\"\"\n",
        "    return genre_series.fillna(\"\").astype(str).str.split(r\"\\s*,\\s*\").apply(\n",
        "        lambda genres: sorted({g.strip() for g in genres if g.strip()})\n",
        "    )\n",
        "\n",
        "print(\"Preprocessing genres...\")\n",
        "y_train_list = preprocess_genres(y_train)\n",
        "y_test_list = preprocess_genres(y_test)\n",
        "\n",
        "print(f\"Sample y_train: {y_train_list.iloc[0]}\")\n",
        "print(f\"Sample y_test: {y_test_list.iloc[0]}\")\n",
        "\n",
        "# Transform text to TF-IDF features\n",
        "print(\"\\nTransforming text to TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=10000, \n",
        "    ngram_range=(1, 2), \n",
        "    stop_words='english'\n",
        ")\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"✓ TF-IDF features: {X_train.shape[1]} features\")\n",
        "\n",
        "# Transform genres to binary labels\n",
        "print(\"\\nTransforming genres to binary labels...\")\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(y_train_list)\n",
        "y_test = mlb.transform(y_test_list)\n",
        "\n",
        "print(f\"✓ Binary labels: {y_train.shape[1]} genres\")\n",
        "print(f\"✓ Training labels shape: {y_train.shape}\")\n",
        "print(f\"✓ Test labels shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "kbest = SelectKBest(score_func=chi2, k=4500)\n",
        "X_train = kbest.fit_transform(X_train, y_train)\n",
        "X_test = kbest.transform(X_test)\n",
        "\n",
        "print(f\"✓ KBest selected {X_train.shape[1]} features\")\n",
        "print(f\"✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "svd = TruncatedSVD(n_components=2000, random_state=42)\n",
        "X_train = svd.fit_transform(X_train)\n",
        "X_test = svd.transform(X_test)\n",
        "\n",
        "print(f\"✓ SVD reduced to {X_train.shape[1]} features\")\n",
        "print(f\"✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d093a087",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total preprocessing parameter combinations: 162\n",
            "Fixed LinearSVC parameters: {'C': 0.1, 'penalty': 'l2', 'loss': 'squared_hinge', 'max_iter': 1000, 'tol': 0.001, 'class_weight': 'balanced', 'dual': False, 'random_state': 42}\n",
            "Estimated time: ~5.4 minutes (assuming ~2 min per config)\n",
            "============================================================\n",
            "\n",
            "Reloading original text data for grid search...\n",
            "\u001b[32m2025-12-14 12:33:18.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoading interim data from /Users/christianfullerton/Developer/Python Workspace/movie_genre_model/data/interim/cleaned_movies.csv...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:33:18.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mLoaded with index column\u001b[0m\n",
            "\u001b[32m2025-12-14 12:33:18.218\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m108\u001b[0m - \u001b[32m\u001b[1m✓ Data loaded successfully: 9087 rows, 2 columns\u001b[0m\n",
            "✓ Loaded original text data: 7269 train, 1818 test\n",
            "\n",
            "Starting Grid Search over Preprocessing Parameters...\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:   3%|▎         | 5/162 [00:27<14:07,  5.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[5/162] max_feat=10000, ngram=(1, 2), k=4500: F1=0.6028, Time=5.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:   6%|▌         | 10/162 [00:55<13:58,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[10/162] max_feat=15000, ngram=(1, 3), k=4500: F1=0.6029, Time=5.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:   9%|▉         | 15/162 [01:21<13:03,  5.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[15/162] max_feat=20000, ngram=(1, 2), k=4500: F1=0.6030, Time=4.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  12%|█▏        | 20/162 [01:50<13:21,  5.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[20/162] max_feat=10000, ngram=(1, 3), k=4500: F1=0.6040, Time=6.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  15%|█▌        | 25/162 [02:16<12:13,  5.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[25/162] max_feat=15000, ngram=(1, 2), k=4500: F1=0.5995, Time=4.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  19%|█▊        | 30/162 [02:44<11:58,  5.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[30/162] max_feat=15000, ngram=(1, 3), k=4500: F1=0.6029, Time=5.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  22%|██▏       | 35/162 [03:10<11:17,  5.34s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[35/162] max_feat=20000, ngram=(1, 2), k=4500: F1=0.6028, Time=5.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  25%|██▍       | 40/162 [03:38<11:12,  5.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[40/162] max_feat=10000, ngram=(1, 3), k=4500: F1=0.6030, Time=5.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  28%|██▊       | 45/162 [04:05<10:33,  5.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[45/162] max_feat=15000, ngram=(1, 2), k=4500: F1=0.6030, Time=5.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  31%|███       | 50/162 [04:33<10:14,  5.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[50/162] max_feat=20000, ngram=(1, 3), k=4500: F1=0.5980, Time=5.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  34%|███▍      | 55/162 [05:00<09:41,  5.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[55/162] max_feat=10000, ngram=(1, 2), k=5000: F1=0.6074, Time=5.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  37%|███▋      | 60/162 [05:29<09:52,  5.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[60/162] max_feat=10000, ngram=(1, 3), k=5000: F1=0.6019, Time=6.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  40%|████      | 65/162 [05:58<09:17,  5.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[65/162] max_feat=15000, ngram=(1, 2), k=5000: F1=0.6017, Time=5.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  43%|████▎     | 70/162 [06:27<08:58,  5.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[70/162] max_feat=20000, ngram=(1, 3), k=5000: F1=0.6056, Time=6.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  46%|████▋     | 75/162 [06:56<08:21,  5.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[75/162] max_feat=10000, ngram=(1, 2), k=5000: F1=0.6067, Time=5.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  49%|████▉     | 80/162 [07:25<08:01,  5.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[80/162] max_feat=15000, ngram=(1, 3), k=5000: F1=0.6049, Time=6.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  52%|█████▏    | 85/162 [07:54<07:25,  5.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[85/162] max_feat=20000, ngram=(1, 2), k=5000: F1=0.5998, Time=5.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  56%|█████▌    | 90/162 [08:24<07:04,  5.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[90/162] max_feat=20000, ngram=(1, 3), k=5000: F1=0.6019, Time=6.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  59%|█████▊    | 95/162 [08:53<06:28,  5.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[95/162] max_feat=10000, ngram=(1, 2), k=5000: F1=0.6017, Time=5.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  62%|██████▏   | 100/162 [09:23<06:07,  5.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[100/162] max_feat=15000, ngram=(1, 3), k=5000: F1=0.6056, Time=6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  65%|██████▍   | 105/162 [09:52<05:30,  5.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[105/162] max_feat=20000, ngram=(1, 2), k=5000: F1=0.6050, Time=5.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  68%|██████▊   | 110/162 [10:23<05:33,  6.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[110/162] max_feat=10000, ngram=(1, 3), k=6000: F1=0.6070, Time=7.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  71%|███████   | 115/162 [10:57<05:12,  6.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[115/162] max_feat=15000, ngram=(1, 2), k=6000: F1=0.6091, Time=6.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  74%|███████▍  | 120/162 [11:31<04:44,  6.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[120/162] max_feat=15000, ngram=(1, 3), k=6000: F1=0.6028, Time=7.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  77%|███████▋  | 125/162 [12:04<04:05,  6.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[125/162] max_feat=20000, ngram=(1, 2), k=6000: F1=0.6039, Time=6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  80%|████████  | 130/162 [12:38<03:37,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[130/162] max_feat=10000, ngram=(1, 3), k=6000: F1=0.6076, Time=7.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  83%|████████▎ | 135/162 [13:12<03:00,  6.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[135/162] max_feat=15000, ngram=(1, 2), k=6000: F1=0.6072, Time=6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  86%|████████▋ | 140/162 [13:46<02:29,  6.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[140/162] max_feat=20000, ngram=(1, 3), k=6000: F1=0.6048, Time=7.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  90%|████████▉ | 145/162 [14:20<01:54,  6.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[145/162] max_feat=10000, ngram=(1, 2), k=6000: F1=0.6074, Time=6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  93%|█████████▎| 150/162 [14:54<01:21,  6.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[150/162] max_feat=10000, ngram=(1, 3), k=6000: F1=0.6028, Time=7.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  96%|█████████▌| 155/162 [15:27<00:46,  6.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[155/162] max_feat=15000, ngram=(1, 2), k=6000: F1=0.6039, Time=6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search:  99%|█████████▉| 160/162 [16:01<00:13,  6.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[160/162] max_feat=20000, ngram=(1, 3), k=6000: F1=0.6070, Time=7.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Grid Search: 100%|██████████| 162/162 [16:15<00:00,  6.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[162/162] max_feat=20000, ngram=(1, 3), k=6000: F1=0.6028, Time=7.3s\n",
            "\n",
            "============================================================\n",
            "Grid Search Complete!\n",
            "============================================================\n",
            "Best F1 Score: 0.6091 (60.91%)\n",
            "\n",
            "Best Preprocessing Configuration:\n",
            "  max_features: 15000\n",
            "  ngram_range: (1, 2)\n",
            "  max_df: 0.6\n",
            "  min_df: 2\n",
            "  k_features: 6000\n",
            "\n",
            "Best Metrics:\n",
            "  F1 Score:       0.6091 (60.91%)\n",
            "  Precision:      0.5469 (54.69%)\n",
            "  Recall:         0.6873 (68.73%)\n",
            "  Hamming Loss:   0.1314 (13.14%)\n",
            "  Jaccard Score:  0.4379 (43.79%)\n",
            "============================================================\n",
            "\n",
            "Top 5 Configurations by F1 Score:\n",
            "============================================================\n",
            " max_features ngram_range  max_df  min_df  k_features       f1  precision   recall\n",
            "        15000      (1, 2)     0.6       2        6000 0.609075   0.546865 0.687256\n",
            "        15000      (1, 2)     0.7       2        6000 0.609075   0.546865 0.687256\n",
            "        15000      (1, 2)     0.8       2        6000 0.609075   0.546865 0.687256\n",
            "        15000      (1, 3)     0.6       2        6000 0.608656   0.546449 0.686846\n",
            "        15000      (1, 3)     0.7       2        6000 0.608656   0.546449 0.686846\n",
            "============================================================\n",
            "\n",
            "✓ Results saved to /Users/christianfullerton/Developer/Python Workspace/movie_genre_model/models/preprocessing_grid_search_results.csv\n",
            "\n",
            "Retraining best model with optimal preprocessing parameters...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-14 12:49:39.771\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m119\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (1818, 6000), y shape (1818, 18), threshold=0.55\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:39.772\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m128\u001b[0m - \u001b[34m\u001b[1mGenerating predictions with threshold 0.55...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:39.975\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m132\u001b[0m - \u001b[34m\u001b[1mDecision scores generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:39.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mProbabilities generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:39.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m140\u001b[0m - \u001b[34m\u001b[1mBinary predictions generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:39.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m143\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:40.006\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\n",
            "============================================================\n",
            "FINAL BEST MODEL METRICS (Test Set)\n",
            "============================================================\n",
            "  F1 Score:       0.5407 (54.07%)\n",
            "  Precision:      0.6628 (66.28%)\n",
            "  Recall:         0.4566 (45.66%)\n",
            "  Hamming Loss:   0.1155 (11.55%)\n",
            "  Jaccard Score:  0.3705 (37.05%)\n",
            "============================================================\n",
            "\u001b[32m2025-12-14 12:49:40.238\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m119\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (7269, 6000), y shape (7269, 18), threshold=0.55\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:40.239\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m128\u001b[0m - \u001b[34m\u001b[1mGenerating predictions with threshold 0.55...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:41.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m132\u001b[0m - \u001b[34m\u001b[1mDecision scores generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:41.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m136\u001b[0m - \u001b[34m\u001b[1mProbabilities generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:41.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m140\u001b[0m - \u001b[34m\u001b[1mBinary predictions generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:41.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m143\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-14 12:49:41.491\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m158\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "## 2. Preprocessing Parameters Grid Search (Fixed LinearSVC)\n",
        "\n",
        "# Import required modules\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from descriptions.modeling.evaluate import evaluate_model\n",
        "from scipy.special import expit\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Fixed LinearSVC parameters (as specified)\n",
        "FIXED_MODEL_PARAMS = {\n",
        "    \"C\": 0.1,\n",
        "    \"penalty\": \"l2\",\n",
        "    \"loss\": \"squared_hinge\",\n",
        "    \"max_iter\": 1000,\n",
        "    \"tol\": 0.001,\n",
        "    \"class_weight\": \"balanced\",\n",
        "    \"dual\": False,\n",
        "    \"random_state\": 42,\n",
        "}\n",
        "\n",
        "# Preprocessing parameter grid to search over\n",
        "preprocess_param_grid = {\n",
        "    'max_features': [10000, 15000, 20000],\n",
        "    'ngram_range': [(1, 2), (1, 3)],\n",
        "    'max_df': [0.6, 0.7, 0.8],\n",
        "    'min_df': [2, 3, 4],\n",
        "    'k_features': [4500, 5000, 6000],\n",
        "}\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = np.prod([len(v) for v in preprocess_param_grid.values()])\n",
        "print(f\"Total preprocessing parameter combinations: {total_combinations}\")\n",
        "print(f\"Fixed LinearSVC parameters: {FIXED_MODEL_PARAMS}\")\n",
        "print(f\"Estimated time: ~{total_combinations * 2 / 60:.1f} minutes (assuming ~2 min per config)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Reload original text data (before preprocessing overwrote variables)\n",
        "# We need the original text series from the train_test_split\n",
        "print(\"\\nReloading original text data for grid search...\")\n",
        "data = load_interim(INTERIM_DATA_DIR / \"cleaned_movies.csv\")\n",
        "X, y = data['description'], data['genre']\n",
        "X_train_text, X_test_text, y_train_text, y_test_text = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "print(f\"✓ Loaded original text data: {len(X_train_text)} train, {len(X_test_text)} test\")\n",
        "\n",
        "# Preprocess genres function\n",
        "def preprocess_genres(genre_series):\n",
        "    \"\"\"Convert genre strings to lists of genre strings.\"\"\"\n",
        "    return genre_series.fillna(\"\").astype(str).str.split(r\"\\s*,\\s*\").apply(\n",
        "        lambda genres: sorted({g.strip() for g in genres if g.strip()})\n",
        "    )\n",
        "\n",
        "# Grid search results storage\n",
        "results = []\n",
        "\n",
        "print(\"\\nStarting Grid Search over Preprocessing Parameters...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Generate all parameter combinations\n",
        "grid = ParameterGrid(preprocess_param_grid)\n",
        "\n",
        "# Iterate over each preprocessing configuration\n",
        "for idx, preprocess_params in enumerate(tqdm(grid, total=total_combinations, desc=\"Grid Search\"), 1):\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Create TF-IDF vectorizer with current parameters\n",
        "        tfidf = TfidfVectorizer(\n",
        "            max_features=preprocess_params['max_features'],\n",
        "            ngram_range=preprocess_params['ngram_range'],\n",
        "            max_df=preprocess_params['max_df'],\n",
        "            min_df=preprocess_params['min_df'],\n",
        "            stop_words='english',\n",
        "            sublinear_tf=True,\n",
        "            use_idf=True\n",
        "        )\n",
        "        \n",
        "        # Transform text to TF-IDF features\n",
        "        X_train_tfidf = tfidf.fit_transform(X_train_text)\n",
        "        X_test_tfidf = tfidf.transform(X_test_text)\n",
        "        \n",
        "        # Transform genres to binary labels\n",
        "        y_train_list = preprocess_genres(y_train_text)\n",
        "        y_test_list = preprocess_genres(y_test_text)\n",
        "        \n",
        "        mlb = MultiLabelBinarizer()\n",
        "        y_train_binary = mlb.fit_transform(y_train_list)\n",
        "        y_test_binary = mlb.transform(y_test_list)\n",
        "        \n",
        "        # Apply feature selection\n",
        "        kbest = SelectKBest(score_func=chi2, k=preprocess_params['k_features'])\n",
        "        X_train_selected = kbest.fit_transform(X_train_tfidf, y_train_binary)\n",
        "        X_test_selected = kbest.transform(X_test_tfidf)\n",
        "        \n",
        "        # Convert to dense arrays for LinearSVC\n",
        "        X_train_dense = X_train_selected.toarray()\n",
        "        X_test_dense = X_test_selected.toarray()\n",
        "        \n",
        "        # Create and train model with FIXED parameters\n",
        "        model = OneVsRestClassifier(\n",
        "            LinearSVC(**FIXED_MODEL_PARAMS)  # Uses your fixed params!\n",
        "        )\n",
        "        model.fit(X_train_dense, y_train_binary)\n",
        "        \n",
        "        # Evaluate on test set\n",
        "        # LinearSVC doesn't have predict_proba, use decision_function + sigmoid\n",
        "        y_scores = model.decision_function(X_test_dense)\n",
        "        y_proba = expit(y_scores)\n",
        "        y_pred = (y_proba >= 0.5).astype(int)\n",
        "        \n",
        "        # Calculate metrics\n",
        "        test_f1 = f1_score(y_test_binary, y_pred, average='micro', zero_division=0)\n",
        "        test_precision = precision_score(y_test_binary, y_pred, average='micro', zero_division=0)\n",
        "        test_recall = recall_score(y_test_binary, y_pred, average='micro', zero_division=0)\n",
        "        test_hamming = hamming_loss(y_test_binary, y_pred)\n",
        "        test_jaccard = jaccard_score(y_test_binary, y_pred, average='micro', zero_division=0)\n",
        "        \n",
        "        elapsed_time = time.time() - start_time\n",
        "        \n",
        "        # Store results\n",
        "        result = {\n",
        "            **preprocess_params,\n",
        "            'f1': test_f1,\n",
        "            'precision': test_precision,\n",
        "            'recall': test_recall,\n",
        "            'hamming_loss': test_hamming,\n",
        "            'jaccard': test_jaccard,\n",
        "            'time_seconds': elapsed_time,\n",
        "        }\n",
        "        results.append(result)\n",
        "        \n",
        "        # Print progress every 5 configurations\n",
        "        if idx % 5 == 0 or idx == total_combinations:\n",
        "            print(f\"\\n[{idx}/{total_combinations}] \"\n",
        "                  f\"max_feat={preprocess_params['max_features']}, \"\n",
        "                  f\"ngram={preprocess_params['ngram_range']}, \"\n",
        "                  f\"k={preprocess_params['k_features']}: \"\n",
        "                  f\"F1={test_f1:.4f}, Time={elapsed_time:.1f}s\")\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"\\nError in configuration {idx}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        continue\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Find best configuration (highest F1 score)\n",
        "best_idx = results_df['f1'].idxmax()\n",
        "best_config = results_df.loc[best_idx]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Grid Search Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Best F1 Score: {best_config['f1']:.4f} ({best_config['f1']*100:.2f}%)\")\n",
        "print(f\"\\nBest Preprocessing Configuration:\")\n",
        "print(f\"  max_features: {best_config['max_features']}\")\n",
        "print(f\"  ngram_range: {best_config['ngram_range']}\")\n",
        "print(f\"  max_df: {best_config['max_df']}\")\n",
        "print(f\"  min_df: {best_config['min_df']}\")\n",
        "print(f\"  k_features: {best_config['k_features']}\")\n",
        "print(f\"\\nBest Metrics:\")\n",
        "print(f\"  F1 Score:       {best_config['f1']:.4f} ({best_config['f1']*100:.2f}%)\")\n",
        "print(f\"  Precision:      {best_config['precision']:.4f} ({best_config['precision']*100:.2f}%)\")\n",
        "print(f\"  Recall:         {best_config['recall']:.4f} ({best_config['recall']*100:.2f}%)\")\n",
        "print(f\"  Hamming Loss:   {best_config['hamming_loss']:.4f} ({best_config['hamming_loss']*100:.2f}%)\")\n",
        "print(f\"  Jaccard Score:  {best_config['jaccard']:.4f} ({best_config['jaccard']*100:.2f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display top 5 configurations\n",
        "print(\"\\nTop 5 Configurations by F1 Score:\")\n",
        "print(\"=\"*60)\n",
        "top_5 = results_df.nlargest(5, 'f1')[['max_features', 'ngram_range', 'max_df', 'min_df', 'k_features', 'f1', 'precision', 'recall']]\n",
        "print(top_5.to_string(index=False))\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv(MODELS_DIR / 'preprocessing_grid_search_results.csv', index=False)\n",
        "print(f\"\\n✓ Results saved to {MODELS_DIR / 'preprocessing_grid_search_results.csv'}\")\n",
        "\n",
        "# Retrain best model for final evaluation\n",
        "print(\"\\nRetraining best model with optimal preprocessing parameters...\")\n",
        "tfidf_best = TfidfVectorizer(\n",
        "    max_features=int(best_config['max_features']),\n",
        "    ngram_range=best_config['ngram_range'],\n",
        "    max_df=best_config['max_df'],\n",
        "    min_df=int(best_config['min_df']),\n",
        "    stop_words='english',\n",
        "    sublinear_tf=True,\n",
        "    use_idf=True\n",
        ")\n",
        "\n",
        "X_train_best = tfidf_best.fit_transform(X_train_text)\n",
        "X_test_best = tfidf_best.transform(X_test_text)\n",
        "\n",
        "y_train_list = preprocess_genres(y_train_text)\n",
        "y_test_list = preprocess_genres(y_test_text)\n",
        "\n",
        "mlb_best = MultiLabelBinarizer()\n",
        "y_train_best = mlb_best.fit_transform(y_train_list)\n",
        "y_test_best = mlb_best.transform(y_test_list)\n",
        "\n",
        "kbest_best = SelectKBest(score_func=chi2, k=int(best_config['k_features']))\n",
        "X_train_best = kbest_best.fit_transform(X_train_best, y_train_best)\n",
        "X_test_best = kbest_best.transform(X_test_best)\n",
        "\n",
        "best_model_svc = OneVsRestClassifier(LinearSVC(**FIXED_MODEL_PARAMS))\n",
        "best_model_svc.fit(X_train_best.toarray(), y_train_best)\n",
        "\n",
        "# Evaluate best model\n",
        "metrics_svc = evaluate_model(best_model_svc, X_test_best.toarray(), y_test_best)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL BEST MODEL METRICS (Test Set)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  F1 Score:       {metrics_svc['f1']:.4f} ({metrics_svc['f1']*100:.2f}%)\")\n",
        "print(f\"  Precision:      {metrics_svc['precision']:.4f} ({metrics_svc['precision']*100:.2f}%)\")\n",
        "print(f\"  Recall:         {metrics_svc['recall']:.4f} ({metrics_svc['recall']*100:.2f}%)\")\n",
        "print(f\"  Hamming Loss:   {metrics_svc['hamming_loss']:.4f} ({metrics_svc['hamming_loss']*100:.2f}%)\")\n",
        "print(f\"  Jaccard Score:  {metrics_svc['jaccard']:.4f} ({metrics_svc['jaccard']*100:.2f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Store for comparison\n",
        "test_metrics = metrics_svc\n",
        "train_metrics = evaluate_model(best_model_svc, X_train_best.toarray(), y_train_best)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4e0e23",
      "metadata": {},
      "source": [
        "## 3. Overfitting Analysis: Cross-Validation, Learning Curves, and Validation Curves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fa96e3",
      "metadata": {},
      "source": [
        "### 3.3. Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1dd5d539",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "VALIDATION CURVE ANALYSIS\n",
            "======================================================================\n",
            "Testing C values: [ 0.01        0.02154435  0.04641589  0.1         0.21544347  0.46415888\n",
            "  1.          2.15443469  4.64158883 10.        ]\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'ClassifierChain' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting C values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC_range\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create base model for validation curve\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m base_model = \u001b[43mClassifierChain\u001b[49m(LinearSVC(random_state=\u001b[32m42\u001b[39m, dual=\u001b[38;5;28;01mFalse\u001b[39;00m, max_iter=\u001b[32m1000\u001b[39m, class_weight=\u001b[33m'\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mComputing validation curve (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Compute validation curve\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'ClassifierChain' is not defined"
          ]
        }
      ],
      "source": [
        "# Validation Curve: How model performance changes with regularization parameter C\n",
        "print(\"=\" * 70)\n",
        "print(\"VALIDATION CURVE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "# Test different C values\n",
        "C_range = np.logspace(-2, 1, 10)  # From 0.01 to 10\n",
        "print(f\"Testing C values: {C_range}\")\n",
        "\n",
        "# Create base model for validation curve\n",
        "base_model = ClassifierChain(LinearSVC(random_state=42, dual=False, max_iter=1000, class_weight='balanced'))\n",
        "\n",
        "print(\"\\nComputing validation curve (this may take a few minutes)...\")\n",
        "\n",
        "# Compute validation curve\n",
        "train_scores_vc, val_scores_vc = validation_curve(\n",
        "    base_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    param_name='estimator__C',\n",
        "    param_range=C_range,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_scores_mean_vc = train_scores_vc.mean(axis=1)\n",
        "train_scores_std_vc = train_scores_vc.std(axis=1)\n",
        "val_scores_mean_vc = val_scores_vc.mean(axis=1)\n",
        "val_scores_std_vc = val_scores_vc.std(axis=1)\n",
        "\n",
        "# Plot validation curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.semilogx(C_range, train_scores_mean_vc, 'o-', color='steelblue', label='Training Score', linewidth=2)\n",
        "ax.fill_between(C_range, train_scores_mean_vc - train_scores_std_vc, train_scores_mean_vc + train_scores_std_vc, alpha=0.2, color='steelblue')\n",
        "ax.semilogx(C_range, val_scores_mean_vc, 'o-', color='coral', label='Cross-Validation Score', linewidth=2)\n",
        "ax.fill_between(C_range, val_scores_mean_vc - val_scores_std_vc, val_scores_mean_vc + val_scores_std_vc, alpha=0.2, color='coral')\n",
        "ax.set_xlabel('C (Regularization Parameter)', fontsize=12)\n",
        "ax.set_ylabel('F1 Score (Micro)', fontsize=12)\n",
        "ax.set_title('Validation Curve: Effect of Regularization (C)', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim([0, 1.0])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal C\n",
        "optimal_idx = np.argmax(val_scores_mean_vc)\n",
        "optimal_C = C_range[optimal_idx]\n",
        "optimal_score = val_scores_mean_vc[optimal_idx]\n",
        "\n",
        "print(f\"\\nValidation Curve Analysis:\")\n",
        "print(f\"  Optimal C: {optimal_C:.4f}\")\n",
        "print(f\"  Optimal CV Score: {optimal_score:.4f}\")\n",
        "print(f\"  Current C (from grid search): {grid_search_svc.best_params_['estimator__C']}\")\n",
        "if abs(optimal_C - grid_search_svc.best_params_['estimator__C']) > 0.5:\n",
        "    print(f\"  ⚠ Consider retraining with C={optimal_C:.4f} for potentially better performance\")\n",
        "else:\n",
        "    print(f\"  ✓ Current C is close to optimal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69f0668",
      "metadata": {},
      "source": [
        "### 3.4. Final Metrics Summary DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad765569",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FINAL METRICS SUMMARY\n",
            "======================================================================\n",
            "Note: Computing cross-validation metrics (cv_summary not found)...\n",
            "\u001b[32m2025-12-11 00:26:07.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (1818, 2000), y shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.314\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (7269, 2000), y shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\n",
            "Final Metrics Summary:\n",
            "           Metric  Train   Test  CV Mean  CV Std  Overfitting Gap\n",
            " F1 Score (Micro) 0.7347 0.5987   0.6101  0.0086           0.1360\n",
            " F1 Score (Macro) 0.7319 0.5389   0.5459  0.0173           0.1930\n",
            "Precision (Micro) 0.6413 0.5276   0.5485  0.0074           0.1137\n",
            "   Recall (Micro) 0.8599 0.6918   0.6875  0.0131           0.1681\n",
            "     Hamming Loss 0.0912 0.1381   0.1290  0.0023          -0.0469\n",
            "    Jaccard Score 0.5806 0.4272      NaN     NaN           0.1534\n",
            "\n",
            "======================================================================\n",
            "MODEL PARAMETERS\n",
            "======================================================================\n",
            "Best Parameters from Grid Search:\n",
            "  estimator__C: 0.1\n",
            "  estimator__class_weight: balanced\n",
            "  estimator__loss: squared_hinge\n",
            "  estimator__max_iter: 1000\n",
            "  estimator__penalty: l2\n",
            "  estimator__tol: 0.001\n",
            "\n",
            "Model Performance Summary:\n",
            "  Train F1: 0.7347\n",
            "  Test F1: 0.5987\n",
            "  CV F1 Mean: 0.6101 ± 0.0086\n",
            "  Overfitting Gap: 0.1360\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Compile all metrics into a comprehensive DataFrame\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL METRICS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check if cv_summary exists (from section 3.1), if not, compute it\n",
        "if 'cv_summary' not in globals():\n",
        "    print(\"Note: Computing cross-validation metrics (cv_summary not found)...\")\n",
        "    from sklearn.model_selection import cross_validate\n",
        "    \n",
        "    scoring = {\n",
        "        'f1_micro': make_scorer(f1_score, average='micro', zero_division=0),\n",
        "        'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
        "        'precision_micro': make_scorer(precision_score, average='micro', zero_division=0),\n",
        "        'recall_micro': make_scorer(recall_score, average='micro', zero_division=0),\n",
        "        'hamming_loss': make_scorer(hamming_loss),\n",
        "    }\n",
        "    \n",
        "    cv_results = cross_validate(\n",
        "        best_model_svc,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        scoring=scoring,\n",
        "        return_train_score=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    cv_summary = {}\n",
        "    for metric in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss']:\n",
        "        train_scores = cv_results[f'train_{metric}']\n",
        "        test_scores = cv_results[f'test_{metric}']\n",
        "        cv_summary[metric] = {\n",
        "            'train_mean': train_scores.mean(),\n",
        "            'train_std': train_scores.std(),\n",
        "            'test_mean': test_scores.mean(),\n",
        "            'test_std': test_scores.std(),\n",
        "            'gap': train_scores.mean() - test_scores.mean(),\n",
        "        }\n",
        "\n",
        "# Get test set metrics\n",
        "test_metrics_final = evaluate_model(best_model_svc, X_test, y_test)\n",
        "train_metrics_final = evaluate_model(best_model_svc, X_train, y_train)\n",
        "\n",
        "# Create comprehensive metrics DataFrame\n",
        "metrics_data = {\n",
        "    'Metric': [\n",
        "        'F1 Score (Micro)',\n",
        "        'F1 Score (Macro)',\n",
        "        'Precision (Micro)',\n",
        "        'Recall (Micro)',\n",
        "        'Hamming Loss',\n",
        "        'Jaccard Score',\n",
        "    ],\n",
        "    'Train': [\n",
        "        train_metrics_final['f1'],\n",
        "        f1_score(y_train, best_model_svc.predict(X_train), average='macro', zero_division=0),\n",
        "        train_metrics_final['precision'],\n",
        "        train_metrics_final['recall'],\n",
        "        train_metrics_final['hamming_loss'],\n",
        "        train_metrics_final['jaccard'],\n",
        "    ],\n",
        "    'Test': [\n",
        "        test_metrics_final['f1'],\n",
        "        f1_score(y_test, best_model_svc.predict(X_test), average='macro', zero_division=0),\n",
        "        test_metrics_final['precision'],\n",
        "        test_metrics_final['recall'],\n",
        "        test_metrics_final['hamming_loss'],\n",
        "        test_metrics_final['jaccard'],\n",
        "    ],\n",
        "    'CV Mean': [\n",
        "        cv_summary['f1_micro']['test_mean'],\n",
        "        cv_summary['f1_macro']['test_mean'],\n",
        "        cv_summary['precision_micro']['test_mean'],\n",
        "        cv_summary['recall_micro']['test_mean'],\n",
        "        cv_summary['hamming_loss']['test_mean'],\n",
        "        None,  # Jaccard not in CV summary\n",
        "    ],\n",
        "    'CV Std': [\n",
        "        cv_summary['f1_micro']['test_std'],\n",
        "        cv_summary['f1_macro']['test_std'],\n",
        "        cv_summary['precision_micro']['test_std'],\n",
        "        cv_summary['recall_micro']['test_std'],\n",
        "        cv_summary['hamming_loss']['test_std'],\n",
        "        None,\n",
        "    ],\n",
        "    'Overfitting Gap': [\n",
        "        train_metrics_final['f1'] - test_metrics_final['f1'],\n",
        "        f1_score(y_train, best_model_svc.predict(X_train), average='macro', zero_division=0) - \n",
        "        f1_score(y_test, best_model_svc.predict(X_test), average='macro', zero_division=0),\n",
        "        train_metrics_final['precision'] - test_metrics_final['precision'],\n",
        "        train_metrics_final['recall'] - test_metrics_final['recall'],\n",
        "        train_metrics_final['hamming_loss'] - test_metrics_final['hamming_loss'],\n",
        "        train_metrics_final['jaccard'] - test_metrics_final['jaccard'],\n",
        "    ],\n",
        "}\n",
        "\n",
        "final_metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Format the DataFrame for better readability\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.4f}' if pd.notna(x) else 'N/A')\n",
        "print(\"\\nFinal Metrics Summary:\")\n",
        "print(final_metrics_df.to_string(index=False))\n",
        "\n",
        "# Add model parameters summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL PARAMETERS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Best Parameters from Grid Search:\")\n",
        "for param, value in grid_search_svc.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"\\nModel Performance Summary:\")\n",
        "print(f\"  Train F1: {train_metrics_final['f1']:.4f}\")\n",
        "print(f\"  Test F1: {test_metrics_final['f1']:.4f}\")\n",
        "print(f\"  CV F1 Mean: {cv_summary['f1_micro']['test_mean']:.4f} ± {cv_summary['f1_micro']['test_std']:.4f}\")\n",
        "print(f\"  Overfitting Gap: {train_metrics_final['f1'] - test_metrics_final['f1']:.4f}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8824856",
      "metadata": {},
      "source": [
        "### 3.1. Cross-Validation for Overfitting Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2560cf72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CROSS-VALIDATION OVERFITTING ANALYSIS\n",
            "======================================================================\n",
            "Using best model with parameters: {'estimator__C': 0.5, 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__penalty': 'l2', 'estimator__tol': 0.001}\n",
            "\n",
            "Performing 5-fold cross-validation...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "CROSS-VALIDATION RESULTS (5-fold)\n",
            "======================================================================\n",
            "Metric               Train Mean   Train Std    Test Mean    Test Std     Gap       \n",
            "----------------------------------------------------------------------\n",
            "f1_micro                 0.7750       0.0036       0.5831       0.0053     0.1920\n",
            "f1_macro                 0.7883       0.0028       0.5201       0.0132     0.2682\n",
            "precision_micro          0.6927       0.0037       0.5280       0.0045     0.1646\n",
            "recall_micro             0.8797       0.0033       0.6510       0.0117     0.2286\n",
            "hamming_loss             0.0750       0.0013       0.1367       0.0008    -0.0617\n",
            "\n",
            "======================================================================\n",
            "OVERFITTING ASSESSMENT\n",
            "======================================================================\n",
            "⚠ HIGH: Overfitting gap is 0.1920 (> 0.15)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Cross-Validation for Overfitting Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"CROSS-VALIDATION OVERFITTING ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Use the best model from grid search\n",
        "print(f\"Using best model with parameters: {grid_search_svc.best_params_}\")\n",
        "\n",
        "# Define scoring metrics for cross-validation\n",
        "scoring = {\n",
        "    'f1_micro': make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
        "    'precision_micro': make_scorer(precision_score, average='micro', zero_division=0),\n",
        "    'recall_micro': make_scorer(recall_score, average='micro', zero_division=0),\n",
        "    'hamming_loss': make_scorer(hamming_loss),\n",
        "}\n",
        "\n",
        "# Perform cross-validation with return_train_score=True to detect overfitting\n",
        "print(\"\\nPerforming 5-fold cross-validation...\")\n",
        "cv_results = cross_validate(\n",
        "    best_model_svc,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=scoring,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std for each metric\n",
        "cv_summary = {}\n",
        "for metric in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss']:\n",
        "    train_scores = cv_results[f'train_{metric}']\n",
        "    test_scores = cv_results[f'test_{metric}']\n",
        "    \n",
        "    cv_summary[metric] = {\n",
        "        'train_mean': train_scores.mean(),\n",
        "        'train_std': train_scores.std(),\n",
        "        'test_mean': test_scores.mean(),\n",
        "        'test_std': test_scores.std(),\n",
        "        'gap': train_scores.mean() - test_scores.mean(),\n",
        "    }\n",
        "\n",
        "# Display cross-validation results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-VALIDATION RESULTS (5-fold)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Metric':<20} {'Train Mean':<12} {'Train Std':<12} {'Test Mean':<12} {'Test Std':<12} {'Gap':<10}\")\n",
        "print(\"-\" * 70)\n",
        "for metric, stats in cv_summary.items():\n",
        "    print(f\"{metric:<20} {stats['train_mean']:>10.4f}   {stats['train_std']:>10.4f}   \"\n",
        "          f\"{stats['test_mean']:>10.4f}   {stats['test_std']:>10.4f}   {stats['gap']:>8.4f}\")\n",
        "\n",
        "# Overfitting assessment\n",
        "overfitting_gap = cv_summary['f1_micro']['gap']\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"OVERFITTING ASSESSMENT\")\n",
        "print(\"=\" * 70)\n",
        "if overfitting_gap < 0.05:\n",
        "    print(f\"✓ EXCELLENT: Overfitting gap is {overfitting_gap:.4f} (< 0.05)\")\n",
        "elif overfitting_gap < 0.10:\n",
        "    print(f\"✓ GOOD: Overfitting gap is {overfitting_gap:.4f} (< 0.10)\")\n",
        "elif overfitting_gap < 0.15:\n",
        "    print(f\"⚠ MODERATE: Overfitting gap is {overfitting_gap:.4f} (0.10-0.15)\")\n",
        "else:\n",
        "    print(f\"⚠ HIGH: Overfitting gap is {overfitting_gap:.4f} (> 0.15)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbb7562",
      "metadata": {},
      "source": [
        "### 3.2. Learning Curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b363784",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "LEARNING CURVE ANALYSIS\n",
            "======================================================================\n",
            "Training sizes: [ 726 1453 2180 2907 3634 4361 5088 5815 6542 7269]\n",
            "\n",
            "Computing learning curve (this may take a few minutes)...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "train_sizes has been interpreted as absolute numbers of training samples and must be within (0, 5815], but is within [726, 7269].",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mComputing learning curve (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Compute learning curve\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m train_sizes_abs, train_scores, val_scores = \u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbest_model_svc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_sizes_abs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf1_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmicro\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Calculate mean and std\u001b[39;00m\n\u001b[32m     28\u001b[39m train_scores_mean = train_scores.mean(axis=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:2028\u001b[39m, in \u001b[36mlearning_curve\u001b[39m\u001b[34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params, params)\u001b[39m\n\u001b[32m   2024\u001b[39m n_max_training_samples = \u001b[38;5;28mlen\u001b[39m(cv_iter[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m   2025\u001b[39m \u001b[38;5;66;03m# Because the lengths of folds can be significantly different, it is\u001b[39;00m\n\u001b[32m   2026\u001b[39m \u001b[38;5;66;03m# not guaranteed that we use all of the available training data when we\u001b[39;00m\n\u001b[32m   2027\u001b[39m \u001b[38;5;66;03m# use the first 'n_max_training_samples' samples.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m train_sizes_abs = \u001b[43m_translate_train_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_max_training_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2029\u001b[39m n_unique_ticks = train_sizes_abs.shape[\u001b[32m0\u001b[39m]\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose > \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:2147\u001b[39m, in \u001b[36m_translate_train_sizes\u001b[39m\u001b[34m(train_sizes, n_max_training_samples)\u001b[39m\n\u001b[32m   2142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2144\u001b[39m         n_min_required_samples <= \u001b[32m0\u001b[39m\n\u001b[32m   2145\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m n_max_required_samples > n_max_training_samples\n\u001b[32m   2146\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2147\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2148\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtrain_sizes has been interpreted as absolute \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2149\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnumbers of training samples and must be within \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2150\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(0, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m], but is within [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2151\u001b[39m             % (\n\u001b[32m   2152\u001b[39m                 n_max_training_samples,\n\u001b[32m   2153\u001b[39m                 n_min_required_samples,\n\u001b[32m   2154\u001b[39m                 n_max_required_samples,\n\u001b[32m   2155\u001b[39m             )\n\u001b[32m   2156\u001b[39m         )\n\u001b[32m   2158\u001b[39m train_sizes_abs = np.unique(train_sizes_abs)\n\u001b[32m   2159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_ticks > train_sizes_abs.shape[\u001b[32m0\u001b[39m]:\n",
            "\u001b[31mValueError\u001b[39m: train_sizes has been interpreted as absolute numbers of training samples and must be within (0, 5815], but is within [726, 7269]."
          ]
        }
      ],
      "source": [
        "# Learning Curve: How model performance changes with training set size\n",
        "print(\"=\" * 70)\n",
        "print(\"LEARNING CURVE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Define training sizes (percentages of training data)\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "train_sizes_abs = (train_sizes * X_train.shape[0]).astype(int)\n",
        "\n",
        "print(f\"Training sizes: {train_sizes_abs}\")\n",
        "print(\"\\nComputing learning curve (this may take a few minutes)...\")\n",
        "\n",
        "# Compute learning curve\n",
        "train_sizes_abs, train_scores, val_scores = learning_curve(\n",
        "    best_model_svc,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_sizes=train_sizes_abs,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_scores_mean = train_scores.mean(axis=1)\n",
        "train_scores_std = train_scores.std(axis=1)\n",
        "val_scores_mean = val_scores.mean(axis=1)\n",
        "val_scores_std = val_scores.std(axis=1)\n",
        "\n",
        "# Plot learning curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(train_sizes_abs, train_scores_mean, 'o-', color='steelblue', label='Training Score', linewidth=2)\n",
        "ax.fill_between(train_sizes_abs, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color='steelblue')\n",
        "ax.plot(train_sizes_abs, val_scores_mean, 'o-', color='coral', label='Cross-Validation Score', linewidth=2)\n",
        "ax.fill_between(train_sizes_abs, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.2, color='coral')\n",
        "ax.set_xlabel('Training Set Size', fontsize=12)\n",
        "ax.set_ylabel('F1 Score (Micro)', fontsize=12)\n",
        "ax.set_title('Learning Curve: LinearSVC', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim([0, 1.0])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze learning curve\n",
        "final_gap = train_scores_mean[-1] - val_scores_mean[-1]\n",
        "print(f\"\\nLearning Curve Analysis:\")\n",
        "print(f\"  Final training score: {train_scores_mean[-1]:.4f}\")\n",
        "print(f\"  Final CV score: {val_scores_mean[-1]:.4f}\")\n",
        "print(f\"  Gap: {final_gap:.4f}\")\n",
        "if val_scores_mean[-1] < val_scores_mean[-2]:\n",
        "    print(\"  ⚠ Model may be overfitting (CV score decreasing)\")\n",
        "elif final_gap > 0.10:\n",
        "    print(f\"  ⚠ Large gap ({final_gap:.4f}) suggests overfitting\")\n",
        "else:\n",
        "    print(f\"  ✓ Good generalization (gap: {final_gap:.4f})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "movie_genre_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
