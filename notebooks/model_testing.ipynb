{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "131c1419",
      "metadata": {},
      "source": [
        "# Model Testing and Comparison Notebook\n",
        "\n",
        "This notebook provides a framework for testing and comparing different machine learning models for movie genre classification.\n",
        "\n",
        "## Features:\n",
        "- Easy model configuration and testing\n",
        "- Automatic metric calculation and comparison\n",
        "- Visualization of results\n",
        "- Support for multiple model types (Logistic Regression, XGBoost, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a1b21c6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ XGBoost available\n",
            "✓ All imports successful\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    f1_score, precision_score, recall_score, \n",
        "    hamming_loss, jaccard_score, confusion_matrix\n",
        ")\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Any\n",
        "import json\n",
        "\n",
        "# Try importing XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "    print(\"✓ XGBoost available\")\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"⚠ XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "# Project imports\n",
        "from descriptions.config import INTERIM_DATA_DIR, MODELS_DIR\n",
        "from descriptions.dataset import load_interim\n",
        "from descriptions.modeling.train import prepare_features_and_labels\n",
        "from descriptions.modeling.preprocess import load_preprocessors\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"✓ All imports successful\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0248b936",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c2febb7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "\u001b[32m2025-12-10 23:22:51.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mLoading interim data from /Users/christianfullerton/Developer/Python Workspace/movie_genre_model/data/interim/cleaned_movies.csv...\u001b[0m\n",
            "\u001b[32m2025-12-10 23:22:51.843\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m103\u001b[0m - \u001b[34m\u001b[1mLoaded with index column\u001b[0m\n",
            "\u001b[32m2025-12-10 23:22:51.844\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_interim\u001b[0m:\u001b[36m108\u001b[0m - \u001b[32m\u001b[1m✓ Data loaded successfully: 9087 rows, 2 columns\u001b[0m\n",
            "✓ Loaded 9087 samples\n",
            "Columns: ['genre', 'description']\n",
            "\n",
            "First few rows:\n",
            "                                     genre  \\\n",
            "movie_name                                   \n",
            "he_hawshank_edemption         Drama, Crime   \n",
            "he_odfather                   Drama, Crime   \n",
            "he_odfather_art_              Drama, Crime   \n",
            "chindlers_ist          Drama, History, War   \n",
            "12_ngry_en                           Drama   \n",
            "\n",
            "                                                             description  \n",
            "movie_name                                                                \n",
            "he_hawshank_edemption  Imprisoned in the 1940s for the double murder ...  \n",
            "he_odfather            Spanning the years 1945 to 1955, a chronicle o...  \n",
            "he_odfather_art_       In the continuing saga of the Corleone crime f...  \n",
            "chindlers_ist          The true story of how businessman Oskar Schind...  \n",
            "12_ngry_en             The defense and the prosecution have rested an...  \n",
            "\n",
            "Splitting data...\n",
            "✓ Data split complete\n"
          ]
        }
      ],
      "source": [
        "# Load and prepare data\n",
        "print(\"Loading data...\")\n",
        "data = load_interim(INTERIM_DATA_DIR / \"cleaned_movies.csv\")\n",
        "print(f\"✓ Loaded {len(data)} samples\")\n",
        "print(f\"Columns: {list(data.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(data.head())\n",
        "\n",
        "# Split data into train and test sets BEFORE preprocessing (prevents data leakage)\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "X, y = data['description'], data['genre']\n",
        "\n",
        "print(\"\\nSplitting data...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
        "print(\"✓ Data split complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "329da199",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing genres...\n",
            "Sample y_train: ['Horror', 'Mystery']\n",
            "Sample y_test: ['Adventure', 'Science Fiction', 'Western']\n",
            "\n",
            "Transforming text to TF-IDF features...\n",
            "✓ TF-IDF features: 10000 features\n",
            "\n",
            "Transforming genres to binary labels...\n",
            "✓ Binary labels: 18 genres\n",
            "✓ Training labels shape: (7269, 18)\n",
            "✓ Test labels shape: (1818, 18)\n",
            "✓ KBest selected 4500 features\n",
            "✓ Training features shape: (7269, 4500)\n",
            "✓ Test features shape: (1818, 4500)\n",
            "✓ SVD reduced to 2000 features\n",
            "✓ Training features shape: (7269, 2000)\n",
            "✓ Test features shape: (1818, 2000)\n"
          ]
        }
      ],
      "source": [
        "# Preprocess data: TF-IDF features and multi-label encoding\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Convert genre strings to lists of genre strings\n",
        "def preprocess_genres(genre_series):\n",
        "    \"\"\"Convert genre strings to lists of genre strings.\"\"\"\n",
        "    return genre_series.fillna(\"\").astype(str).str.split(r\"\\s*,\\s*\").apply(\n",
        "        lambda genres: sorted({g.strip() for g in genres if g.strip()})\n",
        "    )\n",
        "\n",
        "print(\"Preprocessing genres...\")\n",
        "y_train_list = preprocess_genres(y_train)\n",
        "y_test_list = preprocess_genres(y_test)\n",
        "\n",
        "print(f\"Sample y_train: {y_train_list.iloc[0]}\")\n",
        "print(f\"Sample y_test: {y_test_list.iloc[0]}\")\n",
        "\n",
        "# Transform text to TF-IDF features\n",
        "print(\"\\nTransforming text to TF-IDF features...\")\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=10000, \n",
        "    ngram_range=(1, 2), \n",
        "    stop_words='english'\n",
        ")\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"✓ TF-IDF features: {X_train.shape[1]} features\")\n",
        "\n",
        "# Transform genres to binary labels\n",
        "print(\"\\nTransforming genres to binary labels...\")\n",
        "mlb = MultiLabelBinarizer()\n",
        "y_train = mlb.fit_transform(y_train_list)\n",
        "y_test = mlb.transform(y_test_list)\n",
        "\n",
        "print(f\"✓ Binary labels: {y_train.shape[1]} genres\")\n",
        "print(f\"✓ Training labels shape: {y_train.shape}\")\n",
        "print(f\"✓ Test labels shape: {y_test.shape}\")\n",
        "\n",
        "\n",
        "kbest = SelectKBest(score_func=chi2, k=4500)\n",
        "X_train = kbest.fit_transform(X_train, y_train)\n",
        "X_test = kbest.transform(X_test)\n",
        "\n",
        "print(f\"✓ KBest selected {X_train.shape[1]} features\")\n",
        "print(f\"✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n",
        "\n",
        "svd = TruncatedSVD(n_components=2000, random_state=42)\n",
        "X_train = svd.fit_transform(X_train)\n",
        "X_test = svd.transform(X_test)\n",
        "\n",
        "print(f\"✓ SVD reduced to {X_train.shape[1]} features\")\n",
        "print(f\"✓ Training features shape: {X_train.shape}\")\n",
        "print(f\"✓ Test features shape: {X_test.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d093a087",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameter combinations: 64\n",
            "With 5-fold CV: 320 model fits\n",
            "Estimated time: ~2.7 minutes\n",
            "\n",
            "Starting Grid Search for LinearSVC...\n",
            "Testing parameter combinations with 5-fold CV\n",
            "============================================================\n",
            "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/multiprocessing/queues.py:122: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  return _ForkingPickler.loads(res)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  46.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  47.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.0s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  38.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.0s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  58.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  57.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  33.7s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  34.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  34.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  33.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  47.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  46.3s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  46.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  55.2s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  55.3s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  54.7s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  34.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  33.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  33.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  53.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  55.2s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  34.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  33.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  33.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.0s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  30.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time=  41.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time=  42.3s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time=  43.2s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time=  42.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time=  43.2s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  48.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  48.7s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  47.7s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  31.0s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  30.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  46.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time=  45.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  30.3s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  32.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  32.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  31.1s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  31.9s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  32.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  33.2s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  44.8s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.5s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  45.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  49.6s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  48.0s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  48.4s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  45.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  38.0s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  39.0s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  35.3s\n",
            "[CV] END estimator__C=0.01, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  45.2s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.1s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  37.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  36.1s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  39.1s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  34.9s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  37.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.6s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.0s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  40.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  39.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  40.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  41.0s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  42.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  41.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  53.2s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  52.9s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  54.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  52.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  45.3s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  41.1s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  39.2s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  41.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  40.3s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  40.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  35.6s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.8s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  34.4s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.0s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.1s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  37.5s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  34.9s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.3s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  33.6s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  53.5s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  53.7s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  53.9s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  55.2s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  54.9s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  47.6s\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.0min\n",
            "[CV] END estimator__C=0.05, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  48.6s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  56.2s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  59.5s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  59.4s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  47.9s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  53.4s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  54.5s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  34.8s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.2s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  34.8s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.5min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  36.6s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  39.5s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time=  39.1s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  39.1s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  40.0s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  38.3s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time=  36.3s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  36.2s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.4s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.2s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.0s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time=  37.1s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  37.1s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.0s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.2s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.8s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time=  35.6s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time=  59.4s\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.1, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.9min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 2.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 3.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 4.0min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 4.0min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=balanced, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.8min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.0min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=1000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.5min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.001; total time= 1.4min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.6min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l1, estimator__tol=0.0001; total time= 1.7min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.001; total time= 1.2min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.3min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.2min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time= 1.1min\n",
            "[CV] END estimator__C=0.5, estimator__class_weight=None, estimator__loss=squared_hinge, estimator__max_iter=2000, estimator__penalty=l2, estimator__tol=0.0001; total time=  58.5s\n",
            "\n",
            "============================================================\n",
            "Grid Search Complete!\n",
            "============================================================\n",
            "Best parameters: {'estimator__C': 0.1, 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__penalty': 'l2', 'estimator__tol': 0.001}\n",
            "Best cross-validation score (F1 micro): 0.6101\n",
            "============================================================\n",
            "\n",
            "Evaluating Best LinearSVC Model...\n",
            "\u001b[32m2025-12-11 00:11:20.648\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (1818, 2000), y shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:20.659\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:20.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:20.922\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:20.991\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\n",
            "============================================================\n",
            "BEST LINEARSVC METRICS (Test Set)\n",
            "============================================================\n",
            "  F1 Score:       0.5987 (59.87%)\n",
            "  Precision:      0.5276 (52.76%)\n",
            "  Recall:         0.6918 (69.18%)\n",
            "  Hamming Loss:   0.1381 (13.81%)\n",
            "  Jaccard Score:  0.4272 (42.72%)\n",
            "============================================================\n",
            "\u001b[32m2025-12-11 00:11:20.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (7269, 2000), y shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:20.993\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:21.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:21.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:11:21.309\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "## 2. LinearSVC Grid Search and Evaluation\n",
        "\n",
        "# Import required modules\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from descriptions.modeling.evaluate import evaluate_model\n",
        "\n",
        "# Create base model with OneVsRestClassifier for multi-label classification\n",
        "model_svc = OneVsRestClassifier(LinearSVC(random_state=42, dual=False))\n",
        "param_grid = {\n",
        "    'estimator__C': [0.01, 0.05, 0.1, 0.5],\n",
        "    'estimator__penalty': ['l1','l2'],\n",
        "    'estimator__loss': ['squared_hinge'],\n",
        "    'estimator__max_iter': [1000, 2000],\n",
        "    'estimator__tol': [1e-3, 1e-4],\n",
        "    'estimator__class_weight': ['balanced', None],\n",
        "}\n",
        "\n",
        "# Calculate total combinations\n",
        "total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
        "print(f\"Total parameter combinations: {total_combinations}\")\n",
        "print(f\"With 5-fold CV: {total_combinations * 5} model fits\")\n",
        "print(f\"Estimated time: ~{total_combinations * 5 * 0.5 / 60:.1f} minutes\")\n",
        "\n",
        "# Create custom scorer for multi-label classification (micro-averaged F1)\n",
        "def multi_label_f1_micro(y_true, y_pred):\n",
        "    \"\"\"Custom scorer for multi-label F1 micro.\"\"\"\n",
        "    return f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "\n",
        "scorer = make_scorer(multi_label_f1_micro)\n",
        "\n",
        "# Grid Search with cross-validation\n",
        "print(\"\\nStarting Grid Search for LinearSVC...\")\n",
        "print(f\"Testing parameter combinations with 5-fold CV\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "grid_search_svc = GridSearchCV(\n",
        "    estimator=model_svc,\n",
        "    param_grid=param_grid,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "grid_search_svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Grid Search Complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Best parameters: {grid_search_svc.best_params_}\")\n",
        "print(f\"Best cross-validation score (F1 micro): {grid_search_svc.best_score_:.4f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get the best model\n",
        "best_model_svc = grid_search_svc.best_estimator_\n",
        "\n",
        "# Evaluate the best model\n",
        "print(\"\\nEvaluating Best LinearSVC Model...\")\n",
        "metrics_svc = evaluate_model(best_model_svc, X_test, y_test)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST LINEARSVC METRICS (Test Set)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"  F1 Score:       {metrics_svc['f1']:.4f} ({metrics_svc['f1']*100:.2f}%)\")\n",
        "print(f\"  Precision:      {metrics_svc['precision']:.4f} ({metrics_svc['precision']*100:.2f}%)\")\n",
        "print(f\"  Recall:         {metrics_svc['recall']:.4f} ({metrics_svc['recall']*100:.2f}%)\")\n",
        "print(f\"  Hamming Loss:   {metrics_svc['hamming_loss']:.4f} ({metrics_svc['hamming_loss']*100:.2f}%)\")\n",
        "print(f\"  Jaccard Score:  {metrics_svc['jaccard']:.4f} ({metrics_svc['jaccard']*100:.2f}%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Store for comparison\n",
        "test_metrics = metrics_svc\n",
        "train_metrics = evaluate_model(best_model_svc, X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e4e0e23",
      "metadata": {},
      "source": [
        "## 3. Overfitting Analysis: Cross-Validation, Learning Curves, and Validation Curves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17fa96e3",
      "metadata": {},
      "source": [
        "### 3.3. Validation Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1dd5d539",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "VALIDATION CURVE ANALYSIS\n",
            "======================================================================\n",
            "Testing C values: [ 0.01        0.02154435  0.04641589  0.1         0.21544347  0.46415888\n",
            "  1.          2.15443469  4.64158883 10.        ]\n",
            "\n",
            "Computing validation curve (this may take a few minutes)...\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Curve Analysis:\n",
            "  Optimal C: 0.2154\n",
            "  Optimal CV Score: 0.6114\n",
            "  Current C (from grid search): 0.1\n",
            "  ✓ Current C is close to optimal\n"
          ]
        }
      ],
      "source": [
        "# Validation Curve: How model performance changes with regularization parameter C\n",
        "print(\"=\" * 70)\n",
        "print(\"VALIDATION CURVE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "# Test different C values\n",
        "C_range = np.logspace(-2, 1, 10)  # From 0.01 to 10\n",
        "print(f\"Testing C values: {C_range}\")\n",
        "\n",
        "# Create base model for validation curve\n",
        "base_model = OneVsRestClassifier(LinearSVC(random_state=42, dual=False, max_iter=1000, class_weight='balanced'))\n",
        "\n",
        "print(\"\\nComputing validation curve (this may take a few minutes)...\")\n",
        "\n",
        "# Compute validation curve\n",
        "train_scores_vc, val_scores_vc = validation_curve(\n",
        "    base_model,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    param_name='estimator__C',\n",
        "    param_range=C_range,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_scores_mean_vc = train_scores_vc.mean(axis=1)\n",
        "train_scores_std_vc = train_scores_vc.std(axis=1)\n",
        "val_scores_mean_vc = val_scores_vc.mean(axis=1)\n",
        "val_scores_std_vc = val_scores_vc.std(axis=1)\n",
        "\n",
        "# Plot validation curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.semilogx(C_range, train_scores_mean_vc, 'o-', color='steelblue', label='Training Score', linewidth=2)\n",
        "ax.fill_between(C_range, train_scores_mean_vc - train_scores_std_vc, train_scores_mean_vc + train_scores_std_vc, alpha=0.2, color='steelblue')\n",
        "ax.semilogx(C_range, val_scores_mean_vc, 'o-', color='coral', label='Cross-Validation Score', linewidth=2)\n",
        "ax.fill_between(C_range, val_scores_mean_vc - val_scores_std_vc, val_scores_mean_vc + val_scores_std_vc, alpha=0.2, color='coral')\n",
        "ax.set_xlabel('C (Regularization Parameter)', fontsize=12)\n",
        "ax.set_ylabel('F1 Score (Micro)', fontsize=12)\n",
        "ax.set_title('Validation Curve: Effect of Regularization (C)', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim([0, 1.0])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal C\n",
        "optimal_idx = np.argmax(val_scores_mean_vc)\n",
        "optimal_C = C_range[optimal_idx]\n",
        "optimal_score = val_scores_mean_vc[optimal_idx]\n",
        "\n",
        "print(f\"\\nValidation Curve Analysis:\")\n",
        "print(f\"  Optimal C: {optimal_C:.4f}\")\n",
        "print(f\"  Optimal CV Score: {optimal_score:.4f}\")\n",
        "print(f\"  Current C (from grid search): {grid_search_svc.best_params_['estimator__C']}\")\n",
        "if abs(optimal_C - grid_search_svc.best_params_['estimator__C']) > 0.5:\n",
        "    print(f\"  ⚠ Consider retraining with C={optimal_C:.4f} for potentially better performance\")\n",
        "else:\n",
        "    print(f\"  ✓ Current C is close to optimal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b69f0668",
      "metadata": {},
      "source": [
        "### 3.4. Final Metrics Summary DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ad765569",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "FINAL METRICS SUMMARY\n",
            "======================================================================\n",
            "Note: Computing cross-validation metrics (cv_summary not found)...\n",
            "\u001b[32m2025-12-11 00:26:07.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (1818, 2000), y shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.314\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (1818, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m116\u001b[0m - \u001b[34m\u001b[1mEvaluating model: X shape (7269, 2000), y shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m125\u001b[0m - \u001b[34m\u001b[1mGenerating predictions from model...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m127\u001b[0m - \u001b[34m\u001b[1mPredictions generated: shape (7269, 18)\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mCalculating evaluation metrics (micro-averaged)...\u001b[0m\n",
            "\u001b[32m2025-12-11 00:26:07.820\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.evaluate\u001b[0m:\u001b[36mevaluate_model\u001b[0m:\u001b[36m145\u001b[0m - \u001b[34m\u001b[1mEvaluation metrics calculated successfully\u001b[0m\n",
            "\n",
            "Final Metrics Summary:\n",
            "           Metric  Train   Test  CV Mean  CV Std  Overfitting Gap\n",
            " F1 Score (Micro) 0.7347 0.5987   0.6101  0.0086           0.1360\n",
            " F1 Score (Macro) 0.7319 0.5389   0.5459  0.0173           0.1930\n",
            "Precision (Micro) 0.6413 0.5276   0.5485  0.0074           0.1137\n",
            "   Recall (Micro) 0.8599 0.6918   0.6875  0.0131           0.1681\n",
            "     Hamming Loss 0.0912 0.1381   0.1290  0.0023          -0.0469\n",
            "    Jaccard Score 0.5806 0.4272      NaN     NaN           0.1534\n",
            "\n",
            "======================================================================\n",
            "MODEL PARAMETERS\n",
            "======================================================================\n",
            "Best Parameters from Grid Search:\n",
            "  estimator__C: 0.1\n",
            "  estimator__class_weight: balanced\n",
            "  estimator__loss: squared_hinge\n",
            "  estimator__max_iter: 1000\n",
            "  estimator__penalty: l2\n",
            "  estimator__tol: 0.001\n",
            "\n",
            "Model Performance Summary:\n",
            "  Train F1: 0.7347\n",
            "  Test F1: 0.5987\n",
            "  CV F1 Mean: 0.6101 ± 0.0086\n",
            "  Overfitting Gap: 0.1360\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Compile all metrics into a comprehensive DataFrame\n",
        "print(\"=\" * 70)\n",
        "print(\"FINAL METRICS SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check if cv_summary exists (from section 3.1), if not, compute it\n",
        "if 'cv_summary' not in globals():\n",
        "    print(\"Note: Computing cross-validation metrics (cv_summary not found)...\")\n",
        "    from sklearn.model_selection import cross_validate\n",
        "    \n",
        "    scoring = {\n",
        "        'f1_micro': make_scorer(f1_score, average='micro', zero_division=0),\n",
        "        'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
        "        'precision_micro': make_scorer(precision_score, average='micro', zero_division=0),\n",
        "        'recall_micro': make_scorer(recall_score, average='micro', zero_division=0),\n",
        "        'hamming_loss': make_scorer(hamming_loss),\n",
        "    }\n",
        "    \n",
        "    cv_results = cross_validate(\n",
        "        best_model_svc,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "        scoring=scoring,\n",
        "        return_train_score=True,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    \n",
        "    cv_summary = {}\n",
        "    for metric in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss']:\n",
        "        train_scores = cv_results[f'train_{metric}']\n",
        "        test_scores = cv_results[f'test_{metric}']\n",
        "        cv_summary[metric] = {\n",
        "            'train_mean': train_scores.mean(),\n",
        "            'train_std': train_scores.std(),\n",
        "            'test_mean': test_scores.mean(),\n",
        "            'test_std': test_scores.std(),\n",
        "            'gap': train_scores.mean() - test_scores.mean(),\n",
        "        }\n",
        "\n",
        "# Get test set metrics\n",
        "test_metrics_final = evaluate_model(best_model_svc, X_test, y_test)\n",
        "train_metrics_final = evaluate_model(best_model_svc, X_train, y_train)\n",
        "\n",
        "# Create comprehensive metrics DataFrame\n",
        "metrics_data = {\n",
        "    'Metric': [\n",
        "        'F1 Score (Micro)',\n",
        "        'F1 Score (Macro)',\n",
        "        'Precision (Micro)',\n",
        "        'Recall (Micro)',\n",
        "        'Hamming Loss',\n",
        "        'Jaccard Score',\n",
        "    ],\n",
        "    'Train': [\n",
        "        train_metrics_final['f1'],\n",
        "        f1_score(y_train, best_model_svc.predict(X_train), average='macro', zero_division=0),\n",
        "        train_metrics_final['precision'],\n",
        "        train_metrics_final['recall'],\n",
        "        train_metrics_final['hamming_loss'],\n",
        "        train_metrics_final['jaccard'],\n",
        "    ],\n",
        "    'Test': [\n",
        "        test_metrics_final['f1'],\n",
        "        f1_score(y_test, best_model_svc.predict(X_test), average='macro', zero_division=0),\n",
        "        test_metrics_final['precision'],\n",
        "        test_metrics_final['recall'],\n",
        "        test_metrics_final['hamming_loss'],\n",
        "        test_metrics_final['jaccard'],\n",
        "    ],\n",
        "    'CV Mean': [\n",
        "        cv_summary['f1_micro']['test_mean'],\n",
        "        cv_summary['f1_macro']['test_mean'],\n",
        "        cv_summary['precision_micro']['test_mean'],\n",
        "        cv_summary['recall_micro']['test_mean'],\n",
        "        cv_summary['hamming_loss']['test_mean'],\n",
        "        None,  # Jaccard not in CV summary\n",
        "    ],\n",
        "    'CV Std': [\n",
        "        cv_summary['f1_micro']['test_std'],\n",
        "        cv_summary['f1_macro']['test_std'],\n",
        "        cv_summary['precision_micro']['test_std'],\n",
        "        cv_summary['recall_micro']['test_std'],\n",
        "        cv_summary['hamming_loss']['test_std'],\n",
        "        None,\n",
        "    ],\n",
        "    'Overfitting Gap': [\n",
        "        train_metrics_final['f1'] - test_metrics_final['f1'],\n",
        "        f1_score(y_train, best_model_svc.predict(X_train), average='macro', zero_division=0) - \n",
        "        f1_score(y_test, best_model_svc.predict(X_test), average='macro', zero_division=0),\n",
        "        train_metrics_final['precision'] - test_metrics_final['precision'],\n",
        "        train_metrics_final['recall'] - test_metrics_final['recall'],\n",
        "        train_metrics_final['hamming_loss'] - test_metrics_final['hamming_loss'],\n",
        "        train_metrics_final['jaccard'] - test_metrics_final['jaccard'],\n",
        "    ],\n",
        "}\n",
        "\n",
        "final_metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "# Format the DataFrame for better readability\n",
        "pd.set_option('display.float_format', lambda x: f'{x:.4f}' if pd.notna(x) else 'N/A')\n",
        "print(\"\\nFinal Metrics Summary:\")\n",
        "print(final_metrics_df.to_string(index=False))\n",
        "\n",
        "# Add model parameters summary\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL PARAMETERS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Best Parameters from Grid Search:\")\n",
        "for param, value in grid_search_svc.best_params_.items():\n",
        "    print(f\"  {param}: {value}\")\n",
        "\n",
        "print(f\"\\nModel Performance Summary:\")\n",
        "print(f\"  Train F1: {train_metrics_final['f1']:.4f}\")\n",
        "print(f\"  Test F1: {test_metrics_final['f1']:.4f}\")\n",
        "print(f\"  CV F1 Mean: {cv_summary['f1_micro']['test_mean']:.4f} ± {cv_summary['f1_micro']['test_std']:.4f}\")\n",
        "print(f\"  Overfitting Gap: {train_metrics_final['f1'] - test_metrics_final['f1']:.4f}\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8824856",
      "metadata": {},
      "source": [
        "### 3.1. Cross-Validation for Overfitting Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2560cf72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "CROSS-VALIDATION OVERFITTING ANALYSIS\n",
            "======================================================================\n",
            "Using best model with parameters: {'estimator__C': 0.1, 'estimator__class_weight': 'balanced', 'estimator__loss': 'squared_hinge', 'estimator__max_iter': 1000, 'estimator__penalty': 'l2', 'estimator__tol': 0.001}\n",
            "\n",
            "Performing 5-fold cross-validation...\n",
            "\n",
            "======================================================================\n",
            "CROSS-VALIDATION RESULTS (5-fold)\n",
            "======================================================================\n",
            "Metric               Train Mean   Train Std    Test Mean    Test Std     Gap       \n",
            "----------------------------------------------------------------------\n",
            "f1_micro                 0.7458       0.0015       0.6101       0.0086     0.1357\n",
            "f1_macro                 0.7490       0.0020       0.5459       0.0173     0.2031\n",
            "precision_micro          0.6550       0.0025       0.5485       0.0074     0.1065\n",
            "recall_micro             0.8659       0.0005       0.6875       0.0131     0.1784\n",
            "hamming_loss             0.0867       0.0008       0.1290       0.0023    -0.0423\n",
            "\n",
            "======================================================================\n",
            "OVERFITTING ASSESSMENT\n",
            "======================================================================\n",
            "⚠ MODERATE: Overfitting gap is 0.1357 (0.10-0.15)\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Cross-Validation for Overfitting Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"CROSS-VALIDATION OVERFITTING ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Use the best model from grid search\n",
        "print(f\"Using best model with parameters: {grid_search_svc.best_params_}\")\n",
        "\n",
        "# Define scoring metrics for cross-validation\n",
        "scoring = {\n",
        "    'f1_micro': make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
        "    'precision_micro': make_scorer(precision_score, average='micro', zero_division=0),\n",
        "    'recall_micro': make_scorer(recall_score, average='micro', zero_division=0),\n",
        "    'hamming_loss': make_scorer(hamming_loss),\n",
        "}\n",
        "\n",
        "# Perform cross-validation with return_train_score=True to detect overfitting\n",
        "print(\"\\nPerforming 5-fold cross-validation...\")\n",
        "cv_results = cross_validate(\n",
        "    best_model_svc,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=scoring,\n",
        "    return_train_score=True,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std for each metric\n",
        "cv_summary = {}\n",
        "for metric in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss']:\n",
        "    train_scores = cv_results[f'train_{metric}']\n",
        "    test_scores = cv_results[f'test_{metric}']\n",
        "    \n",
        "    cv_summary[metric] = {\n",
        "        'train_mean': train_scores.mean(),\n",
        "        'train_std': train_scores.std(),\n",
        "        'test_mean': test_scores.mean(),\n",
        "        'test_std': test_scores.std(),\n",
        "        'gap': train_scores.mean() - test_scores.mean(),\n",
        "    }\n",
        "\n",
        "# Display cross-validation results\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-VALIDATION RESULTS (5-fold)\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Metric':<20} {'Train Mean':<12} {'Train Std':<12} {'Test Mean':<12} {'Test Std':<12} {'Gap':<10}\")\n",
        "print(\"-\" * 70)\n",
        "for metric, stats in cv_summary.items():\n",
        "    print(f\"{metric:<20} {stats['train_mean']:>10.4f}   {stats['train_std']:>10.4f}   \"\n",
        "          f\"{stats['test_mean']:>10.4f}   {stats['test_std']:>10.4f}   {stats['gap']:>8.4f}\")\n",
        "\n",
        "# Overfitting assessment\n",
        "overfitting_gap = cv_summary['f1_micro']['gap']\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"OVERFITTING ASSESSMENT\")\n",
        "print(\"=\" * 70)\n",
        "if overfitting_gap < 0.05:\n",
        "    print(f\"✓ EXCELLENT: Overfitting gap is {overfitting_gap:.4f} (< 0.05)\")\n",
        "elif overfitting_gap < 0.10:\n",
        "    print(f\"✓ GOOD: Overfitting gap is {overfitting_gap:.4f} (< 0.10)\")\n",
        "elif overfitting_gap < 0.15:\n",
        "    print(f\"⚠ MODERATE: Overfitting gap is {overfitting_gap:.4f} (0.10-0.15)\")\n",
        "else:\n",
        "    print(f\"⚠ HIGH: Overfitting gap is {overfitting_gap:.4f} (> 0.15)\")\n",
        "print(\"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fbb7562",
      "metadata": {},
      "source": [
        "### 3.2. Learning Curve\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "4b363784",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "LEARNING CURVE ANALYSIS\n",
            "======================================================================\n",
            "Training sizes: [ 726 1453 2180 2907 3634 4361 5088 5815 6542 7269]\n",
            "\n",
            "Computing learning curve (this may take a few minutes)...\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "train_sizes has been interpreted as absolute numbers of training samples and must be within (0, 5815], but is within [726, 7269].",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mComputing learning curve (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Compute learning curve\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m train_sizes_abs, train_scores, val_scores = \u001b[43mlearning_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbest_model_svc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_sizes_abs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKFold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf1_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmicro\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Calculate mean and std\u001b[39;00m\n\u001b[32m     28\u001b[39m train_scores_mean = train_scores.mean(axis=\u001b[32m1\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:2028\u001b[39m, in \u001b[36mlearning_curve\u001b[39m\u001b[34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times, fit_params, params)\u001b[39m\n\u001b[32m   2024\u001b[39m n_max_training_samples = \u001b[38;5;28mlen\u001b[39m(cv_iter[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m   2025\u001b[39m \u001b[38;5;66;03m# Because the lengths of folds can be significantly different, it is\u001b[39;00m\n\u001b[32m   2026\u001b[39m \u001b[38;5;66;03m# not guaranteed that we use all of the available training data when we\u001b[39;00m\n\u001b[32m   2027\u001b[39m \u001b[38;5;66;03m# use the first 'n_max_training_samples' samples.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2028\u001b[39m train_sizes_abs = \u001b[43m_translate_train_sizes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_max_training_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2029\u001b[39m n_unique_ticks = train_sizes_abs.shape[\u001b[32m0\u001b[39m]\n\u001b[32m   2030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose > \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:2147\u001b[39m, in \u001b[36m_translate_train_sizes\u001b[39m\u001b[34m(train_sizes, n_max_training_samples)\u001b[39m\n\u001b[32m   2142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2143\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2144\u001b[39m         n_min_required_samples <= \u001b[32m0\u001b[39m\n\u001b[32m   2145\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m n_max_required_samples > n_max_training_samples\n\u001b[32m   2146\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2147\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2148\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtrain_sizes has been interpreted as absolute \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2149\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnumbers of training samples and must be within \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2150\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(0, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m], but is within [\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m].\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2151\u001b[39m             % (\n\u001b[32m   2152\u001b[39m                 n_max_training_samples,\n\u001b[32m   2153\u001b[39m                 n_min_required_samples,\n\u001b[32m   2154\u001b[39m                 n_max_required_samples,\n\u001b[32m   2155\u001b[39m             )\n\u001b[32m   2156\u001b[39m         )\n\u001b[32m   2158\u001b[39m train_sizes_abs = np.unique(train_sizes_abs)\n\u001b[32m   2159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_ticks > train_sizes_abs.shape[\u001b[32m0\u001b[39m]:\n",
            "\u001b[31mValueError\u001b[39m: train_sizes has been interpreted as absolute numbers of training samples and must be within (0, 5815], but is within [726, 7269]."
          ]
        }
      ],
      "source": [
        "# Learning Curve: How model performance changes with training set size\n",
        "print(\"=\" * 70)\n",
        "print(\"LEARNING CURVE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "# Define training sizes (percentages of training data)\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "train_sizes_abs = (train_sizes * X_train.shape[0]).astype(int)\n",
        "\n",
        "print(f\"Training sizes: {train_sizes_abs}\")\n",
        "print(\"\\nComputing learning curve (this may take a few minutes)...\")\n",
        "\n",
        "# Compute learning curve\n",
        "train_sizes_abs, train_scores, val_scores = learning_curve(\n",
        "    best_model_svc,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    train_sizes=train_sizes_abs,\n",
        "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    scoring=make_scorer(f1_score, average='micro', zero_division=0),\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_scores_mean = train_scores.mean(axis=1)\n",
        "train_scores_std = train_scores.std(axis=1)\n",
        "val_scores_mean = val_scores.mean(axis=1)\n",
        "val_scores_std = val_scores.std(axis=1)\n",
        "\n",
        "# Plot learning curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(train_sizes_abs, train_scores_mean, 'o-', color='steelblue', label='Training Score', linewidth=2)\n",
        "ax.fill_between(train_sizes_abs, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color='steelblue')\n",
        "ax.plot(train_sizes_abs, val_scores_mean, 'o-', color='coral', label='Cross-Validation Score', linewidth=2)\n",
        "ax.fill_between(train_sizes_abs, val_scores_mean - val_scores_std, val_scores_mean + val_scores_std, alpha=0.2, color='coral')\n",
        "ax.set_xlabel('Training Set Size', fontsize=12)\n",
        "ax.set_ylabel('F1 Score (Micro)', fontsize=12)\n",
        "ax.set_title('Learning Curve: LinearSVC', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='best', fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim([0, 1.0])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analyze learning curve\n",
        "final_gap = train_scores_mean[-1] - val_scores_mean[-1]\n",
        "print(f\"\\nLearning Curve Analysis:\")\n",
        "print(f\"  Final training score: {train_scores_mean[-1]:.4f}\")\n",
        "print(f\"  Final CV score: {val_scores_mean[-1]:.4f}\")\n",
        "print(f\"  Gap: {final_gap:.4f}\")\n",
        "if val_scores_mean[-1] < val_scores_mean[-2]:\n",
        "    print(\"  ⚠ Model may be overfitting (CV score decreasing)\")\n",
        "elif final_gap > 0.10:\n",
        "    print(f\"  ⚠ Large gap ({final_gap:.4f}) suggests overfitting\")\n",
        "else:\n",
        "    print(f\"  ✓ Good generalization (gap: {final_gap:.4f})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "movie_genre_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
