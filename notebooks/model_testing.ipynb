{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0aeb0256",
      "metadata": {},
      "source": [
        "# Model Testing: MultinomialNB, Logistic Regression, and SGD Tuning\n",
        "\n",
        "This notebook tunes MultinomialNB, Logistic Regression, and SGD classifiers for movie genre classification and compares them with the baseline LinearSVC model.\n",
        "\n",
        "## Objectives:\n",
        "1. Hyperparameter tuning for MultinomialNB (with cross-validation overfitting checks)\n",
        "2. Hyperparameter tuning for Logistic Regression (with cross-validation overfitting checks)\n",
        "3. Hyperparameter tuning for SGD (with cross-validation overfitting checks)\n",
        "4. Comparison with baseline LinearSVC model\n",
        "5. Comprehensive evaluation metrics\n",
        "6. Voting Classifier ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc640c0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports and Setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path().resolve().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, validation_curve\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import (\n",
        "    f1_score, \n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    hamming_loss, \n",
        "    jaccard_score,\n",
        "    make_scorer\n",
        ")\n",
        "from scipy.stats import loguniform, randint, uniform\n",
        "import time\n",
        "\n",
        "# Project imports\n",
        "from descriptions.config import INTERIM_DATA_DIR, MODELS_DIR\n",
        "from descriptions.dataset import load_interim\n",
        "from descriptions.modeling.train import prepare_features_and_labels, train_test_split_data\n",
        "from descriptions.modeling.model import build_model, load_model\n",
        "\n",
        "# Set style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úì Imports complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845529c1",
      "metadata": {},
      "source": [
        "## 1. Load and Prepare Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5afc3b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load interim data\n",
        "print(\"Loading data...\")\n",
        "data = load_interim()\n",
        "print(f\"‚úì Loaded {len(data)} samples\")\n",
        "\n",
        "# Prepare features and labels\n",
        "print(\"\\nPreparing features and labels...\")\n",
        "X, y, vectorizer, mlb, normalizer, feature_selector = prepare_features_and_labels(\n",
        "    data,\n",
        "    vectorizer=None,\n",
        "    mlb=None,\n",
        "    normalizer=None,\n",
        "    feature_selector=None,\n",
        "    k_features=4500\n",
        ")\n",
        "\n",
        "print(f\"‚úì Features shape: {X.shape}\")\n",
        "print(f\"‚úì Labels shape: {y.shape}\")\n",
        "print(f\"‚úì Number of genres: {len(mlb.classes_)}\")\n",
        "print(f\"\\nGenres: {list(mlb.classes_)}\")\n",
        "\n",
        "# Split into train/test (use same random_state as training: 42)\n",
        "print(\"\\nSplitting data into train/test sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split_data(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì Data split complete:\")\n",
        "print(f\"  - Training samples: {len(X_train)}\")\n",
        "print(f\"  - Test samples: {len(X_test)}\")\n",
        "\n",
        "# Convert to numpy arrays for sklearn\n",
        "X_train_array = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
        "X_test_array = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "014c6507",
      "metadata": {},
      "source": [
        "## 2. Baseline: LinearSVC Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42246f19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train baseline LinearSVC model\n",
        "print(\"Training baseline LinearSVC model...\")\n",
        "baseline_params = {\n",
        "    'C': 0.1,\n",
        "    'penalty': 'l2',\n",
        "    'loss': 'squared_hinge',\n",
        "    'max_iter': 1000,\n",
        "    'tol': 1e-3,\n",
        "    'class_weight': 'balanced',\n",
        "    'dual': False,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "baseline_model = build_model(**baseline_params)\n",
        "\n",
        "start_time = time.time()\n",
        "baseline_model.fit(X_train_array, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"‚úì Baseline model trained in {training_time:.2f} seconds\")\n",
        "\n",
        "# Get predictions\n",
        "# LinearSVC doesn't have predict_proba, so we use decision_function and convert to probabilities\n",
        "from scipy.special import expit\n",
        "y_scores_baseline = baseline_model.decision_function(X_test_array)\n",
        "y_proba_baseline = expit(y_scores_baseline)\n",
        "y_pred_baseline = baseline_model.predict(X_test_array)\n",
        "\n",
        "# Evaluate baseline\n",
        "baseline_metrics = {\n",
        "    'f1_micro': f1_score(y_test, y_pred_baseline, average='micro'),\n",
        "    'f1_macro': f1_score(y_test, y_pred_baseline, average='macro'),\n",
        "    'precision_micro': precision_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "    'recall_micro': recall_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "    'hamming_loss': hamming_loss(y_test, y_pred_baseline),\n",
        "    'jaccard_score': jaccard_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "}\n",
        "\n",
        "print(\"\\nüìä BASELINE LINEARSVC MODEL METRICS\")\n",
        "print(\"=\" * 70)\n",
        "for metric, value in baseline_metrics.items():\n",
        "    print(f\"  {metric:20s}: {value:.4f} ({value * 100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6535154",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation Curve for LinearSVC\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VALIDATION CURVE: LinearSVC (C Parameter)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create base LinearSVC model with same parameters as baseline (except C which we'll vary)\n",
        "base_svc = LinearSVC(\n",
        "    penalty='l2',\n",
        "    loss='squared_hinge',\n",
        "    max_iter=1000,\n",
        "    tol=1e-3,\n",
        "    class_weight='balanced',\n",
        "    dual=False,\n",
        "    random_state=42\n",
        ")\n",
        "svc_model = OneVsRestClassifier(base_svc)\n",
        "\n",
        "# Use F1-micro as the scoring metric (same as MultinomialNB)\n",
        "scorer_svc = make_scorer(f1_score, average='micro', zero_division=0)\n",
        "\n",
        "# Create a range of C values to test\n",
        "# Use log scale for better visualization (C typically ranges from 1e-3 to 1e2)\n",
        "C_range = np.logspace(-3, 2, 20)  # From 0.001 to 100, 20 points\n",
        "\n",
        "print(f\"\\nComputing validation curve for C values...\")\n",
        "print(f\"  C range: {C_range[0]:.4f} to {C_range[-1]:.4f}\")\n",
        "print(f\"  Number of points: {len(C_range)}\")\n",
        "print(f\"  CV folds: 5\")\n",
        "\n",
        "# Compute validation curve\n",
        "train_scores_svc, val_scores_svc = validation_curve(\n",
        "    svc_model,\n",
        "    X_train_array,\n",
        "    y_train,\n",
        "    param_name='estimator__C',\n",
        "    param_range=C_range,\n",
        "    cv=5,\n",
        "    scoring=scorer_svc,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std for train and validation scores\n",
        "train_mean_svc = np.mean(train_scores_svc, axis=1)\n",
        "train_std_svc = np.std(train_scores_svc, axis=1)\n",
        "val_mean_svc = np.mean(val_scores_svc, axis=1)\n",
        "val_std_svc = np.std(val_scores_svc, axis=1)\n",
        "\n",
        "# Find best C from validation curve\n",
        "best_C_idx = np.argmax(val_mean_svc)\n",
        "best_C_val = C_range[best_C_idx]\n",
        "best_val_score_svc = val_mean_svc[best_C_idx]\n",
        "\n",
        "print(f\"\\n  Best C from validation curve: {best_C_val:.4f}\")\n",
        "print(f\"  Best validation score: {best_val_score_svc:.4f}\")\n",
        "\n",
        "# Plot validation curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot training scores\n",
        "ax.plot(C_range, train_mean_svc, 'o-', color='#3498db', label='Training Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(C_range, train_mean_svc - train_std_svc, train_mean_svc + train_std_svc, alpha=0.2, color='#3498db')\n",
        "\n",
        "# Plot validation scores\n",
        "ax.plot(C_range, val_mean_svc, 'o-', color='#e74c3c', label='Validation Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(C_range, val_mean_svc - val_std_svc, val_mean_svc + val_std_svc, alpha=0.2, color='#e74c3c')\n",
        "\n",
        "# Mark best C\n",
        "ax.axvline(x=best_C_val, color='#2ecc71', linestyle='--', linewidth=2, label=f'Best C ({best_C_val:.4f})')\n",
        "\n",
        "# Mark C from baseline model\n",
        "baseline_C = baseline_params['C']\n",
        "ax.axvline(x=baseline_C, color='#f39c12', linestyle='--', linewidth=2, \n",
        "           label=f'Baseline C ({baseline_C:.4f})')\n",
        "\n",
        "ax.set_xlabel('C (Regularization Parameter)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('F1-Micro Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('LinearSVC Validation Curve: C Parameter', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.set_xscale('log')  # Log scale for better visualization\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.set_ylim([0, max(max(train_mean_svc), max(val_mean_svc)) * 1.1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Validation curve generated\")\n",
        "\n",
        "# Print gap analysis\n",
        "gap_at_best = train_mean_svc[best_C_idx] - val_mean_svc[best_C_idx]\n",
        "baseline_C_idx = np.argmin(np.abs(C_range - baseline_C))\n",
        "gap_at_baseline = train_mean_svc[baseline_C_idx] - val_mean_svc[baseline_C_idx]\n",
        "\n",
        "print(f\"\\n  Gap at best C ({best_C_val:.4f}): {gap_at_best:.4f} ({gap_at_best * 100:.2f}%)\")\n",
        "print(f\"  Gap at baseline C ({baseline_C:.4f}): {gap_at_baseline:.4f} ({gap_at_baseline * 100:.2f}%)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f2315f",
      "metadata": {},
      "source": [
        "## 3. RidgeClassifier Hyperparameter Tuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faf61685",
      "metadata": {},
      "outputs": [],
      "source": [
        "# RidgeClassifier Hyperparameter Tuning\n",
        "print(\"=\" * 70)\n",
        "print(\"HYPERPARAMETER TUNING: RidgeClassifier\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create base RidgeClassifier model\n",
        "# RidgeClassifier uses alpha for regularization (higher alpha = more regularization)\n",
        "# It's similar to LinearSVC but uses Ridge regression instead of SVM\n",
        "base_ridge = RidgeClassifier(\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    solver='auto'  # Automatically choose best solver\n",
        ")\n",
        "ridge_model = OneVsRestClassifier(base_ridge)\n",
        "\n",
        "# Use F1-micro as the scoring metric (same as other models)\n",
        "scorer_ridge = make_scorer(f1_score, average='micro', zero_division=0)\n",
        "\n",
        "# Define parameter grid for RidgeClassifier\n",
        "# Alpha is the regularization strength (inverse of C in LinearSVC)\n",
        "ridge_param_grid = {\n",
        "    'estimator__alpha': np.logspace(-2, 2, 20)  # From 0.01 to 100, 20 points on log scale\n",
        "}\n",
        "\n",
        "print(\"\\nStarting GridSearchCV for RidgeClassifier...\")\n",
        "print(f\"  Parameter grid: alpha range from {ridge_param_grid['estimator__alpha'][0]:.4f} to {ridge_param_grid['estimator__alpha'][-1]:.4f}\")\n",
        "print(f\"  Scoring metric: F1-micro\")\n",
        "print(f\"  CV folds: 5\")\n",
        "print(\"\\n  (This may take a few minutes...)\")\n",
        "\n",
        "# GridSearchCV\n",
        "ridge_grid_search = GridSearchCV(\n",
        "    estimator=ridge_model,\n",
        "    param_grid=ridge_param_grid,\n",
        "    cv=5,\n",
        "    scoring=scorer_ridge,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True  # Enable train scores for overfitting analysis\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "ridge_grid_search.fit(X_train_array, y_train)\n",
        "tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úì Tuning complete in {tuning_time:.2f} seconds\")\n",
        "print(f\"  Best F1-micro (CV): {ridge_grid_search.best_score_:.4f}\")\n",
        "print(f\"  Best parameters: {ridge_grid_search.best_params_}\")\n",
        "\n",
        "# Get best model\n",
        "ridge_model_tuned = ridge_grid_search.best_estimator_\n",
        "\n",
        "# Cross-validation overfitting check\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-VALIDATION OVERFITTING CHECK: RidgeClassifier\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get CV scores from GridSearchCV (validation scores)\n",
        "best_cv_score_ridge = ridge_grid_search.best_score_\n",
        "best_cv_std_ridge = ridge_grid_search.cv_results_['std_test_score'][ridge_grid_search.best_index_]\n",
        "\n",
        "# Get training scores from GridSearchCV\n",
        "best_train_score_ridge = ridge_grid_search.cv_results_['mean_train_score'][ridge_grid_search.best_index_]\n",
        "best_train_std_ridge = ridge_grid_search.cv_results_['std_train_score'][ridge_grid_search.best_index_]\n",
        "\n",
        "# Calculate overfitting gap\n",
        "overfitting_gap_ridge = best_train_score_ridge - best_cv_score_ridge\n",
        "\n",
        "print(f\"\\n  Validation Score (CV): {best_cv_score_ridge:.4f} ¬± {best_cv_std_ridge:.4f}\")\n",
        "print(f\"  Training Score (CV):    {best_train_score_ridge:.4f} ¬± {best_train_std_ridge:.4f}\")\n",
        "print(f\"  Overfitting Gap:        {overfitting_gap_ridge:.4f} ({overfitting_gap_ridge * 100:.2f}%)\")\n",
        "\n",
        "if overfitting_gap_ridge > 0.05:  # 5% threshold\n",
        "    print(f\"  ‚ö†Ô∏è  WARNING: Potential overfitting detected (gap > 5%)\")\n",
        "elif overfitting_gap_ridge > 0.02:  # 2% threshold\n",
        "    print(f\"  ‚ö†Ô∏è  CAUTION: Moderate overfitting gap (2-5%)\")\n",
        "else:\n",
        "    print(f\"  ‚úÖ Good generalization (overfitting gap < 2%)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aaa2db5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation Curve for RidgeClassifier\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VALIDATION CURVE: RidgeClassifier (Alpha Parameter)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create a range of alpha values to test\n",
        "# Use a wider range for better visualization\n",
        "alpha_range_ridge = np.logspace(-2, 2, 20)  # From 0.01 to 100, 20 points\n",
        "\n",
        "print(f\"\\nComputing validation curve for alpha values...\")\n",
        "print(f\"  Alpha range: {alpha_range_ridge[0]:.4f} to {alpha_range_ridge[-1]:.4f}\")\n",
        "print(f\"  Number of points: {len(alpha_range_ridge)}\")\n",
        "print(f\"  CV folds: 5\")\n",
        "\n",
        "# Compute validation curve\n",
        "train_scores_ridge, val_scores_ridge = validation_curve(\n",
        "    ridge_model,\n",
        "    X_train_array,\n",
        "    y_train,\n",
        "    param_name='estimator__alpha',\n",
        "    param_range=alpha_range_ridge,\n",
        "    cv=5,\n",
        "    scoring=scorer_ridge,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std for train and validation scores\n",
        "train_mean_ridge = np.mean(train_scores_ridge, axis=1)\n",
        "train_std_ridge = np.std(train_scores_ridge, axis=1)\n",
        "val_mean_ridge = np.mean(val_scores_ridge, axis=1)\n",
        "val_std_ridge = np.std(val_scores_ridge, axis=1)\n",
        "\n",
        "# Find best alpha from validation curve\n",
        "best_alpha_idx_ridge = np.argmax(val_mean_ridge)\n",
        "best_alpha_val_ridge = alpha_range_ridge[best_alpha_idx_ridge]\n",
        "best_val_score_ridge = val_mean_ridge[best_alpha_idx_ridge]\n",
        "\n",
        "print(f\"\\n  Best alpha from validation curve: {best_alpha_val_ridge:.4f}\")\n",
        "print(f\"  Best validation score: {best_val_score_ridge:.4f}\")\n",
        "\n",
        "# Plot validation curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot training scores\n",
        "ax.plot(alpha_range_ridge, train_mean_ridge, 'o-', color='#3498db', label='Training Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(alpha_range_ridge, train_mean_ridge - train_std_ridge, train_mean_ridge + train_std_ridge, alpha=0.2, color='#3498db')\n",
        "\n",
        "# Plot validation scores\n",
        "ax.plot(alpha_range_ridge, val_mean_ridge, 'o-', color='#e74c3c', label='Validation Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(alpha_range_ridge, val_mean_ridge - val_std_ridge, val_mean_ridge + val_std_ridge, alpha=0.2, color='#e74c3c')\n",
        "\n",
        "# Mark best alpha\n",
        "ax.axvline(x=best_alpha_val_ridge, color='#2ecc71', linestyle='--', linewidth=2, label=f'Best Alpha ({best_alpha_val_ridge:.4f})')\n",
        "\n",
        "# Mark alpha from GridSearchCV if available\n",
        "if 'estimator__alpha' in ridge_grid_search.best_params_:\n",
        "    best_alpha_gs = ridge_grid_search.best_params_['estimator__alpha']\n",
        "    ax.axvline(x=best_alpha_gs, color='#f39c12', linestyle='--', linewidth=2, \n",
        "               label=f'GridSearch Best ({best_alpha_gs:.4f})')\n",
        "\n",
        "ax.set_xlabel('Alpha (Regularization Parameter)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('F1-Micro Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('RidgeClassifier Validation Curve: Alpha Parameter', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.set_xscale('log')  # Log scale for better visualization\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.set_ylim([0, max(max(train_mean_ridge), max(val_mean_ridge)) * 1.1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Validation curve generated\")\n",
        "\n",
        "# Print gap analysis\n",
        "gap_at_best_ridge = train_mean_ridge[best_alpha_idx_ridge] - val_mean_ridge[best_alpha_idx_ridge]\n",
        "print(f\"\\n  Gap at best alpha ({best_alpha_val_ridge:.4f}): {gap_at_best_ridge:.4f} ({gap_at_best_ridge * 100:.2f}%)\")\n",
        "\n",
        "# Generate predictions\n",
        "print(\"\\nGenerating predictions with tuned RidgeClassifier...\")\n",
        "y_pred_ridge = ridge_model_tuned.predict(X_test_array)\n",
        "print(\"‚úì Predictions generated\")\n",
        "\n",
        "# Evaluate tuned RidgeClassifier\n",
        "ridge_metrics = {\n",
        "    'f1_micro': f1_score(y_test, y_pred_ridge, average='micro'),\n",
        "    'f1_macro': f1_score(y_test, y_pred_ridge, average='macro'),\n",
        "    'precision_micro': precision_score(y_test, y_pred_ridge, average='micro', zero_division=0),\n",
        "    'recall_micro': recall_score(y_test, y_pred_ridge, average='micro', zero_division=0),\n",
        "    'hamming_loss': hamming_loss(y_test, y_pred_ridge),\n",
        "    'jaccard_score': jaccard_score(y_test, y_pred_ridge, average='micro', zero_division=0),\n",
        "}\n",
        "\n",
        "print(\"\\nüìä TUNED RIDGECLASSIFIER MODEL METRICS (Test Set)\")\n",
        "print(\"=\" * 70)\n",
        "for metric, value in ridge_metrics.items():\n",
        "    print(f\"  {metric:20s}: {value:.4f} ({value * 100:.2f}%)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aba7f0a5",
      "metadata": {},
      "source": [
        "## 4. MultinomialNB Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c75cf66c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MultinomialNB Hyperparameter Tuning\n",
        "print(\"=\" * 70)\n",
        "print(\"HYPERPARAMETER TUNING: MultinomialNB\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Define parameter grid for MultinomialNB\n",
        "nb_param_grid = {\n",
        "    'estimator__alpha': np.linspace(0.04, 0.02, 10),  # Smoothing parameter\n",
        "    'estimator__fit_prior': [False],  # Whether to learn class prior probabilities\n",
        "}\n",
        "\n",
        "# Create base MultinomialNB model\n",
        "base_nb = MultinomialNB()\n",
        "nb_model = OneVsRestClassifier(base_nb)\n",
        "\n",
        "# Use F1-micro as the scoring metric (appropriate for multi-label)\n",
        "scorer = make_scorer(f1_score, average='micro', zero_division=0)\n",
        "\n",
        "print(\"\\nStarting RandomizedSearchCV for MultinomialNB...\")\n",
        "print(f\"  Parameter grid: {nb_param_grid}\")\n",
        "print(f\"  Scoring metric: F1-micro\")\n",
        "print(f\"  CV folds: 5\")\n",
        "print(f\"  n_iter: 50\")\n",
        "print(\"\\n  (This may take a few minutes...)\")\n",
        "\n",
        "# RandomizedSearchCV\n",
        "nb_random_search = GridSearchCV(\n",
        "    estimator=nb_model,\n",
        "    param_grid=nb_param_grid,\n",
        "    cv=5,\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    return_train_score=True  # Enable train scores for overfitting analysis\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "nb_random_search.fit(X_train_array, y_train)\n",
        "tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úì Tuning complete in {tuning_time:.2f} seconds\")\n",
        "print(f\"  Best F1-micro (CV): {nb_random_search.best_score_:.4f}\")\n",
        "print(f\"  Best parameters: {nb_random_search.best_params_}\")\n",
        "\n",
        "# Get best model\n",
        "nb_model_tuned = nb_random_search.best_estimator_\n",
        "\n",
        "# Cross-validation overfitting check\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CROSS-VALIDATION OVERFITTING CHECK: MultinomialNB\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Get CV scores from RandomizedSearchCV (validation scores)\n",
        "best_cv_score = nb_random_search.best_score_\n",
        "best_cv_std = nb_random_search.cv_results_['std_test_score'][nb_random_search.best_index_]\n",
        "\n",
        "# Get training scores from RandomizedSearchCV\n",
        "best_train_score = nb_random_search.cv_results_['mean_train_score'][nb_random_search.best_index_]\n",
        "best_train_std = nb_random_search.cv_results_['std_train_score'][nb_random_search.best_index_]\n",
        "\n",
        "# Calculate overfitting gap\n",
        "overfitting_gap = best_train_score - best_cv_score\n",
        "\n",
        "print(f\"\\n  Validation Score (CV): {best_cv_score:.4f} ¬± {best_cv_std:.4f}\")\n",
        "print(f\"  Training Score (CV):    {best_train_score:.4f} ¬± {best_train_std:.4f}\")\n",
        "print(f\"  Overfitting Gap:        {overfitting_gap:.4f} ({overfitting_gap * 100:.2f}%)\")\n",
        "\n",
        "if overfitting_gap > 0.05:  # 5% threshold\n",
        "    print(f\"  ‚ö†Ô∏è  WARNING: Potential overfitting detected (gap > 5%)\")\n",
        "elif overfitting_gap > 0.02:  # 2% threshold\n",
        "    print(f\"  ‚ö†Ô∏è  CAUTION: Moderate overfitting gap (2-5%)\")\n",
        "else:\n",
        "    print(f\"  ‚úÖ Good generalization (overfitting gap < 2%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e74e8a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation Curve\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VALIDATION CURVE: MultinomialNB (Alpha Parameter)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create a range of alpha values to test\n",
        "# Use a wider range for better visualization\n",
        "alpha_range = np.logspace(-3, 1, 20)  # From 0.001 to 10, 20 points\n",
        "\n",
        "print(f\"\\nComputing validation curve for alpha values...\")\n",
        "print(f\"  Alpha range: {alpha_range[0]:.4f} to {alpha_range[-1]:.4f}\")\n",
        "print(f\"  Number of points: {len(alpha_range)}\")\n",
        "print(f\"  CV folds: 5\")\n",
        "\n",
        "# Compute validation curve\n",
        "train_scores, val_scores = validation_curve(\n",
        "    nb_model,\n",
        "    X_train_array,\n",
        "    y_train,\n",
        "    param_name='estimator__alpha',\n",
        "    param_range=alpha_range,\n",
        "    cv=5,\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Calculate mean and std for train and validation scores\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# Find best alpha from validation curve\n",
        "best_alpha_idx = np.argmax(val_mean)\n",
        "best_alpha_val = alpha_range[best_alpha_idx]\n",
        "best_val_score = val_mean[best_alpha_idx]\n",
        "\n",
        "print(f\"\\n  Best alpha from validation curve: {best_alpha_val:.4f}\")\n",
        "print(f\"  Best validation score: {best_val_score:.4f}\")\n",
        "\n",
        "# Plot validation curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Plot training scores\n",
        "ax.plot(alpha_range, train_mean, 'o-', color='#3498db', label='Training Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(alpha_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color='#3498db')\n",
        "\n",
        "# Plot validation scores\n",
        "ax.plot(alpha_range, val_mean, 'o-', color='#e74c3c', label='Validation Score', linewidth=2, markersize=6)\n",
        "ax.fill_between(alpha_range, val_mean - val_std, val_mean + val_std, alpha=0.2, color='#e74c3c')\n",
        "\n",
        "# Mark best alpha\n",
        "ax.axvline(x=best_alpha_val, color='#2ecc71', linestyle='--', linewidth=2, label=f'Best Alpha ({best_alpha_val:.4f})')\n",
        "\n",
        "# Mark alpha from RandomizedSearchCV if available\n",
        "if 'estimator__alpha' in nb_random_search.best_params_:\n",
        "    best_alpha_rs = nb_random_search.best_params_['estimator__alpha']\n",
        "    ax.axvline(x=best_alpha_rs, color='#f39c12', linestyle='--', linewidth=2, \n",
        "               label=f'RandomizedSearch Best ({best_alpha_rs:.4f})')\n",
        "\n",
        "ax.set_xlabel('Alpha (Smoothing Parameter)', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('F1-Micro Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title('MultinomialNB Validation Curve: Alpha Parameter', fontsize=14, fontweight='bold', pad=15)\n",
        "ax.set_xscale('log')  # Log scale for better visualization\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend(loc='best', fontsize=10)\n",
        "ax.set_ylim([0, max(max(train_mean), max(val_mean)) * 1.1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Validation curve generated\")\n",
        "\n",
        "# Generate predictions\n",
        "print(\"\\nGenerating predictions with tuned MultinomialNB...\")\n",
        "y_proba_nb = nb_model_tuned.predict_proba(X_test_array)\n",
        "y_pred_nb = nb_model_tuned.predict(X_test_array)\n",
        "print(\"‚úì Predictions generated\")\n",
        "\n",
        "# Evaluate tuned MultinomialNB\n",
        "nb_metrics = {\n",
        "    'f1_micro': f1_score(y_test, y_pred_nb, average='micro'),\n",
        "    'f1_macro': f1_score(y_test, y_pred_nb, average='macro'),\n",
        "    'precision_micro': precision_score(y_test, y_pred_nb, average='micro', zero_division=0),\n",
        "    'recall_micro': recall_score(y_test, y_pred_nb, average='micro', zero_division=0),\n",
        "    'hamming_loss': hamming_loss(y_test, y_pred_nb),\n",
        "    'jaccard_score': jaccard_score(y_test, y_pred_nb, average='micro', zero_division=0),\n",
        "}\n",
        "\n",
        "print(\"\\nüìä TUNED MULTINOMIALNB MODEL METRICS (Test Set)\")\n",
        "print(\"=\" * 70)\n",
        "for metric, value in nb_metrics.items():\n",
        "    print(f\"  {metric:20s}: {value:.4f} ({value * 100:.2f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "movie_genre_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
