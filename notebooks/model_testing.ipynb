{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e51a4953",
      "metadata": {},
      "source": [
        "# Model Testing: VotingClassifier Ensemble\n",
        "\n",
        "This notebook tests whether a VotingClassifier ensemble (combining LinearSVC and LogisticRegression) improves metrics compared to a baseline LinearSVC model.\n",
        "\n",
        "## Approach\n",
        "1. Load and prepare data (train/test split)\n",
        "2. Feature engineering: TF-IDF + Normalizer + SelectKBest\n",
        "3. Train baseline LinearSVC model\n",
        "4. Train VotingClassifier ensemble (LinearSVC + LogisticRegression)\n",
        "5. Compare metrics and performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a2210918",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m2025-12-19 22:48:29.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/christianfullerton/Developer/Python Workspace/movie_genre_model\u001b[0m\n",
            "/Users/christianfullerton/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/mlflow/utils/requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources  # noqa: TID251\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Imports complete (module reloaded)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import expit  # Sigmoid function for converting scores to probabilities\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    hamming_loss,\n",
        "    jaccard_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from descriptions.config import MODELS_DIR, RAW_DATA_DIR\n",
        "from descriptions.dataset import load_data\n",
        "from descriptions.modeling.preprocess import _generate_descriptions, _generate_targets\n",
        "\n",
        "# Reload module to pick up any code changes\n",
        "import importlib\n",
        "import descriptions.modeling.preprocess\n",
        "importlib.reload(descriptions.modeling.preprocess)\n",
        "from descriptions.modeling.preprocess import _generate_descriptions, _generate_targets\n",
        "\n",
        "print(\"✓ Imports complete (module reloaded)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8634a7a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading raw data...\n",
            "\u001b[32m2025-12-19 22:48:45.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mLoading raw data from /Users/christianfullerton/Developer/Python Workspace/movie_genre_model/data/raw/top_movies.csv...\u001b[0m\n",
            "\u001b[32m2025-12-19 22:48:45.452\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m70\u001b[0m - \u001b[32m\u001b[1m✓ Data loaded successfully: 9420 rows, 3 columns\u001b[0m\n",
            "\u001b[32m2025-12-19 22:48:45.453\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.dataset\u001b[0m:\u001b[36mload_data\u001b[0m:\u001b[36m73\u001b[0m - \u001b[34m\u001b[1mColumns: ['movie_name', 'genre', 'description']\u001b[0m\n",
            "✓ Loaded 9420 samples\n",
            "  Columns: ['movie_name', 'genre', 'description']\n",
            "  Sample description: Imprisoned in the 1940s for the double murder of his wife and her lover, upstanding banker Andy Dufr...\n"
          ]
        }
      ],
      "source": [
        "# Load raw data\n",
        "print(\"Loading raw data...\")\n",
        "data = load_data()\n",
        "print(f\"✓ Loaded {len(data)} samples\")\n",
        "print(f\"  Columns: {list(data.columns)}\")\n",
        "print(f\"  Sample description: {data['description'].iloc[0][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c60f3378",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Splitting data (test_size=0.2, random_state=42)...\n",
            "✓ Train: 7536 samples, Test: 1884 samples\n"
          ]
        }
      ],
      "source": [
        "# Split data into train and test sets BEFORE preprocessing (prevents data leakage)\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "print(f\"\\nSplitting data (test_size={TEST_SIZE}, random_state={RANDOM_STATE})...\")\n",
        "data_train, data_test = train_test_split(\n",
        "    data, test_size=TEST_SIZE, random_state=RANDOM_STATE, shuffle=True\n",
        ")\n",
        "# Reset index to ensure clean integer indexing\n",
        "data_train = data_train.reset_index(drop=True)\n",
        "data_test = data_test.reset_index(drop=True)\n",
        "print(f\"✓ Train: {len(data_train)} samples, Test: {len(data_test)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a9e94a08",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "STEP 1: Generating Multi-Label Targets\n",
            "======================================================================\n",
            "\u001b[32m2025-12-16 12:36:59.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mGenerating multi-label targets from 7536 samples...\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mStarting genre preprocessing: cleaning and splitting genre strings\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.163\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m48\u001b[0m - \u001b[34m\u001b[1mFilling missing genres with empty strings\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.168\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m52\u001b[0m - \u001b[33m\u001b[1mFound 1 samples with missing genres (filled with empty string)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSplitting genre strings by comma and cleaning\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.211\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m60\u001b[0m - \u001b[32m\u001b[1mGenre preprocessing complete: 7536 samples processed, average 2.66 genres per sample\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m89\u001b[0m - \u001b[34m\u001b[1mCreating and fitting new MultiLabelBinarizer\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m91\u001b[0m - \u001b[1mAnalyzing genre frequencies (removing genres < 5.0%)...\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1m  Removing 'Music': 2.95% (222 samples)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1m  Removing 'TV Movie': 1.19% (90 samples)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1m  Removing 'War': 3.40% (256 samples)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1m  Removing 'Western': 1.49% (112 samples)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m109\u001b[0m - \u001b[1mIdentified 4 genres to remove: ['Music', 'TV Movie', 'War', 'Western']\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.239\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m121\u001b[0m - \u001b[33m\u001b[1m24 samples lost all genres after filtering and will be removed\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m127\u001b[0m - \u001b[1mRemoved 24 samples with no genres\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.244\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m130\u001b[0m - \u001b[34m\u001b[1mFitting MultiLabelBinarizer on filtered genre lists\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mMultiLabelBinarizer fitted: 14 unique genre labels identified\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mGenres kept: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Mystery', 'Romance', 'Science Fiction', 'Thriller']\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.252\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_targets\u001b[0m:\u001b[36m151\u001b[0m - \u001b[32m\u001b[1mTargets generated: shape (7512, 14) (samples × labels)\u001b[0m\n",
            "\n",
            "Generating test targets manually...\n",
            "\u001b[32m2025-12-16 12:36:59.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mStarting genre preprocessing: cleaning and splitting genre strings\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m48\u001b[0m - \u001b[34m\u001b[1mFilling missing genres with empty strings\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.263\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m52\u001b[0m - \u001b[33m\u001b[1mFound 2 samples with missing genres (filled with empty string)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.263\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m54\u001b[0m - \u001b[34m\u001b[1mSplitting genre strings by comma and cleaning\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.268\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_preprocess_genres\u001b[0m:\u001b[36m60\u001b[0m - \u001b[32m\u001b[1mGenre preprocessing complete: 1884 samples processed, average 2.63 genres per sample\u001b[0m\n",
            "  Removed 6 samples with no genres after filtering\n",
            "\n",
            "✓ Generated targets\n",
            "  Train labels: (7512, 14)\n",
            "  Test labels: (1878, 14)\n",
            "  Number of genres: 14\n",
            "  Genres: ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'History', 'Horror']...\n"
          ]
        }
      ],
      "source": [
        "# Generate targets first (to get filtered indices and MultiLabelBinarizer)\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 1: Generating Multi-Label Targets\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "min_genre_percentage = 5.0\n",
        "# Note: _generate_targets returns (y, mlb, filtered_index) - order matters!\n",
        "y_train, mlb, filtered_index_train = _generate_targets(\n",
        "    data_train, min_genre_percentage=min_genre_percentage\n",
        ")\n",
        "\n",
        "# Manually handle test targets to avoid closure issues with mlb.classes_\n",
        "print(\"\\nGenerating test targets manually...\")\n",
        "from descriptions.modeling.preprocess import _preprocess_genres\n",
        "df_test = _preprocess_genres(data_test)\n",
        "genres_list_test = df_test[\"genre\"]\n",
        "\n",
        "# Filter genres to only those in mlb.classes_ (extract classes to avoid closure issue)\n",
        "mlb_classes_set = set(mlb.classes_)\n",
        "genres_list_filtered_test = [sorted({g for g in genres if g in mlb_classes_set}) for genres in genres_list_test]\n",
        "\n",
        "# Remove samples that lost all genres\n",
        "keep_mask_test = [len(genres) > 0 for genres in genres_list_filtered_test]\n",
        "genres_list_filtered_test = [g for g, keep in zip(genres_list_filtered_test, keep_mask_test) if keep]\n",
        "filtered_index_test = data_test.index[keep_mask_test].tolist()\n",
        "\n",
        "# Transform using mlb\n",
        "y_test = mlb.transform(genres_list_filtered_test)\n",
        "print(f\"  Removed {sum(not k for k in keep_mask_test)} samples with no genres after filtering\")\n",
        "\n",
        "print(f\"\\n✓ Generated targets\")\n",
        "print(f\"  Train labels: {y_train.shape}\")\n",
        "print(f\"  Test labels: {y_test.shape}\")\n",
        "print(f\"  Number of genres: {len(mlb.classes_)}\")\n",
        "print(f\"  Genres: {list(mlb.classes_)[:10]}...\" if len(mlb.classes_) > 10 else f\"  Genres: {list(mlb.classes_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "93670c6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "STEP 2: Generating TF-IDF Features\n",
            "======================================================================\n",
            "  Train samples (after filtering): 7512\n",
            "  Test samples (after filtering): 1878\n",
            "\u001b[32m2025-12-16 12:36:59.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_descriptions\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mGenerating TF-IDF features from 7512 movie descriptions...\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.309\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_descriptions\u001b[0m:\u001b[36m179\u001b[0m - \u001b[34m\u001b[1mCreating and fitting new TfidfVectorizer with default parameters\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.309\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36mbuild_preprocessor\u001b[0m:\u001b[36m218\u001b[0m - \u001b[34m\u001b[1mBuilding preprocessing components: TfidfVectorizer, MultiLabelBinarizer, Normalizer, and SelectKBest\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.310\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36mbuild_preprocessor\u001b[0m:\u001b[36m229\u001b[0m - \u001b[34m\u001b[1mTfidfVectorizer configured: max_features=10000, ngram_range=(1,3), sublinear_tf=True, max_df=0.7, min_df=3\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36mbuild_preprocessor\u001b[0m:\u001b[36m237\u001b[0m - \u001b[34m\u001b[1mNormalizer configured: L2 norm (normalizes each sample to unit length)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:36:59.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36mbuild_preprocessor\u001b[0m:\u001b[36m240\u001b[0m - \u001b[34m\u001b[1mSelectKBest configured: chi2 test, k=4500 features\u001b[0m\n",
            "\u001b[32m2025-12-16 12:37:01.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_descriptions\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mTfidfVectorizer fitted: 10000 features extracted (max_features=10000)\u001b[0m\n",
            "\u001b[32m2025-12-16 12:37:01.132\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mdescriptions.modeling.preprocess\u001b[0m:\u001b[36m_generate_descriptions\u001b[0m:\u001b[36m202\u001b[0m - \u001b[32m\u001b[1mDescription features generated: sparse matrix shape (7512, 10000)\u001b[0m\n",
            "  ✓ TF-IDF features generated\n",
            "  Train shape: (7512, 10000)\n",
            "  Test shape: (1878, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Generate TF-IDF features for filtered data\n",
        "print(\"=\" * 70)\n",
        "print(\"STEP 2: Generating TF-IDF Features\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Filter data to match filtered indices\n",
        "data_train_filtered = data_train.loc[filtered_index_train].reset_index(drop=True)\n",
        "data_test_filtered = data_test.loc[filtered_index_test].reset_index(drop=True)\n",
        "\n",
        "print(f\"  Train samples (after filtering): {len(data_train_filtered)}\")\n",
        "print(f\"  Test samples (after filtering): {len(data_test_filtered)}\")\n",
        "\n",
        "# Generate TF-IDF features - fit on train\n",
        "X_train_combined, vectorizer = _generate_descriptions(data_train_filtered)\n",
        "\n",
        "# Transform test data using the fitted vectorizer\n",
        "X_test_combined = vectorizer.transform(data_test_filtered['description'].fillna(\"\").astype(str))\n",
        "\n",
        "print(f\"  ✓ TF-IDF features generated\")\n",
        "print(f\"  Train shape: {X_train_combined.shape}\")\n",
        "print(f\"  Test shape: {X_test_combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2039fb37",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 3: Applying L2 Normalization\n",
            "======================================================================\n",
            "✓ Normalization applied (L2 norm per sample)\n",
            "  Train shape: (7512, 10000)\n",
            "  Test shape: (1878, 10000)\n"
          ]
        }
      ],
      "source": [
        "# Apply L2 normalization\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 3: Applying L2 Normalization\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "normalizer = Normalizer(norm='l2')\n",
        "X_train_combined = normalizer.fit_transform(X_train_combined)\n",
        "X_test_combined = normalizer.transform(X_test_combined)\n",
        "print(f\"✓ Normalization applied (L2 norm per sample)\")\n",
        "print(f\"  Train shape: {X_train_combined.shape}\")\n",
        "print(f\"  Test shape: {X_test_combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d6b7d4c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 4: Feature Selection (SelectKBest with chi2)\n",
            "======================================================================\n",
            "\n",
            "Selecting top 8000 features using chi2...\n",
            "  Input shape: (7512, 10000)\n",
            "  Target shape: (7512, 14) (multi-label)\n",
            "  (This may take a few minutes)\n",
            "  Creating feature selector...\n",
            "  Fitting feature selector on training data...\n",
            "  ✓ Feature selector fitted in 0.12 seconds\n",
            "  Transforming training and test sets...\n",
            "\n",
            "✓ Feature selection complete!\n",
            "  Train shape: (7512, 8000)\n",
            "  Test shape: (1878, 8000)\n"
          ]
        }
      ],
      "source": [
        "# Feature Selection: SelectKBest with chi2 for Multi-Label Classification\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 4: Feature Selection (SelectKBest with chi2)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "K_FEATURES = 8000\n",
        "print(f\"\\nSelecting top {K_FEATURES} features using chi2...\")\n",
        "print(f\"  Input shape: {X_train_combined.shape}\")\n",
        "print(f\"  Target shape: {y_train.shape} (multi-label)\")\n",
        "print(\"  (This may take a few minutes)\")\n",
        "\n",
        "def chi2_multilabel(X, y):\n",
        "    \"\"\"Chi2 scoring function for multi-label classification\"\"\"\n",
        "    scores_list = []\n",
        "    pvalues_list = []\n",
        "    for label_idx in range(y.shape[1]):\n",
        "        y_single = y[:, label_idx].ravel()\n",
        "        chi2_scores, chi2_pvalues = chi2(X, y_single)\n",
        "        scores_list.append(chi2_scores)\n",
        "        pvalues_list.append(chi2_pvalues)\n",
        "    scores_array = np.array(scores_list).T\n",
        "    pvalues_array = np.array(pvalues_list).T\n",
        "    max_scores = np.max(scores_array, axis=1)\n",
        "    min_pvalues = np.min(pvalues_array, axis=1)\n",
        "    return max_scores, min_pvalues\n",
        "\n",
        "print(\"  Creating feature selector...\")\n",
        "feature_selector = SelectKBest(score_func=chi2_multilabel, k=K_FEATURES)\n",
        "print(\"  Fitting feature selector on training data...\")\n",
        "start_time = time.time()\n",
        "feature_selector.fit(X_train_combined, y_train)\n",
        "fit_time = time.time() - start_time\n",
        "print(f\"  ✓ Feature selector fitted in {fit_time:.2f} seconds\")\n",
        "print(\"  Transforming training and test sets...\")\n",
        "X_train_final = feature_selector.transform(X_train_combined)\n",
        "X_test_final = feature_selector.transform(X_test_combined)\n",
        "print(f\"\\n✓ Feature selection complete!\")\n",
        "print(f\"  Train shape: {X_train_final.shape}\")\n",
        "print(f\"  Test shape: {X_test_final.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "edadaaca",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Configuration:\n",
            "  Base parameters: {'C': 0.1, 'penalty': 'l2', 'loss': 'squared_hinge', 'max_iter': 1000, 'tol': 0.001, 'class_weight': 'balanced', 'dual': False, 'random_state': 42}\n",
            "  Prediction threshold: 0.55\n",
            "  Number of labels: 14\n"
          ]
        }
      ],
      "source": [
        "# Model parameters (from your existing model)\n",
        "MODEL_PARAMS = {\n",
        "    'C': 0.1,\n",
        "    'penalty': 'l2',\n",
        "    'loss': 'squared_hinge',\n",
        "    'max_iter': 1000,\n",
        "    'tol': 1e-3,\n",
        "    'class_weight': 'balanced',\n",
        "    'dual': False,\n",
        "    'random_state': 42,\n",
        "}\n",
        "\n",
        "# Threshold for converting probabilities to binary predictions\n",
        "THRESHOLD = 0.55\n",
        "\n",
        "print(\"Model Configuration:\")\n",
        "print(f\"  Base parameters: {MODEL_PARAMS}\")\n",
        "print(f\"  Prediction threshold: {THRESHOLD}\")\n",
        "print(f\"  Number of labels: {len(mlb.classes_)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "482eb3b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 5: Training Baseline LinearSVC Model\n",
            "======================================================================\n",
            "Training baseline model on 7512 samples...\n",
            "✓ Baseline model trained in 0.25 seconds\n",
            "Generating predictions...\n",
            "✓ Baseline predictions generated\n"
          ]
        }
      ],
      "source": [
        "# Train Baseline LinearSVC Model\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 5: Training Baseline LinearSVC Model\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "baseline_svc = LinearSVC(**MODEL_PARAMS)\n",
        "baseline_model = OneVsRestClassifier(baseline_svc)\n",
        "\n",
        "print(f\"Training baseline model on {X_train_final.shape[0]} samples...\")\n",
        "start_time = time.time()\n",
        "baseline_model.fit(X_train_final, y_train)\n",
        "training_time = time.time() - start_time\n",
        "print(f\"✓ Baseline model trained in {training_time:.2f} seconds\")\n",
        "\n",
        "# Get decision function scores and convert to probabilities using sigmoid\n",
        "print(\"Generating predictions...\")\n",
        "y_scores_baseline = baseline_model.decision_function(X_test_final)\n",
        "# Convert scores to probabilities using sigmoid (expit)\n",
        "y_proba_baseline = expit(y_scores_baseline)\n",
        "y_pred_baseline = (y_proba_baseline >= THRESHOLD).astype(int)\n",
        "\n",
        "print(\"✓ Baseline predictions generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5d1ec3fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "STEP 6: Training VotingClassifier Ensemble\n",
            "======================================================================\n",
            "Training ensemble model on 7512 samples...\n",
            "  This will take longer as it trains multiple models...\n",
            "  (CalibratedClassifierCV adds cross-validation, making it slower)\n",
            "✓ Ensemble model trained in 1.21 seconds\n",
            "Generating predictions...\n",
            "✓ Ensemble predictions generated\n"
          ]
        }
      ],
      "source": [
        "# Train VotingClassifier Ensemble (LinearSVC + LogisticRegression)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STEP 6: Training VotingClassifier Ensemble\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Create individual estimators\n",
        "# Note: LinearSVC doesn't have predict_proba, so we wrap it with CalibratedClassifierCV\n",
        "# to enable soft voting (probability-based voting)\n",
        "base_svc = LinearSVC(**MODEL_PARAMS)\n",
        "svc_estimator = CalibratedClassifierCV(base_svc, method='sigmoid', cv=3)\n",
        "\n",
        "lr_estimator = LogisticRegression(\n",
        "    C=0.1,\n",
        "    max_iter=1000,\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    solver='lbfgs',  # Good default for multi-class\n",
        ")\n",
        "\n",
        "# Create voting classifier with soft voting (uses probabilities)\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('svc', svc_estimator),\n",
        "        ('lr', lr_estimator),\n",
        "    ],\n",
        "    voting='soft'  # Use soft voting for probabilities\n",
        ")\n",
        "\n",
        "# Wrap in OneVsRestClassifier for multi-label classification\n",
        "ensemble_model = OneVsRestClassifier(voting_clf)\n",
        "\n",
        "print(f\"Training ensemble model on {X_train_final.shape[0]} samples...\")\n",
        "print(\"  This will take longer as it trains multiple models...\")\n",
        "print(\"  (CalibratedClassifierCV adds cross-validation, making it slower)\")\n",
        "start_time = time.time()\n",
        "ensemble_model.fit(X_train_final, y_train)\n",
        "training_time = time.time() - start_time\n",
        "print(f\"✓ Ensemble model trained in {training_time:.2f} seconds\")\n",
        "\n",
        "# Generate predictions (voting classifier returns probabilities directly)\n",
        "print(\"Generating predictions...\")\n",
        "y_proba_ensemble = ensemble_model.predict_proba(X_test_final)\n",
        "y_pred_ensemble = (y_proba_ensemble >= THRESHOLD).astype(int)\n",
        "\n",
        "print(\"✓ Ensemble predictions generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "0ee39981",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "BASELINE LINEARSVC MODEL METRICS\n",
            "======================================================================\n",
            "  f1_micro            : 0.5519 (55.19%)\n",
            "  f1_macro            : 0.5376 (53.76%)\n",
            "  precision_micro     : 0.6764 (67.64%)\n",
            "  recall_micro        : 0.4661 (46.61%)\n",
            "  hamming_loss        : 0.1375 (13.75%)\n",
            "  jaccard_score       : 0.3811 (38.11%)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Baseline Model\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"BASELINE LINEARSVC MODEL METRICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "baseline_metrics = {\n",
        "    'f1_micro': f1_score(y_test, y_pred_baseline, average='micro'),\n",
        "    'f1_macro': f1_score(y_test, y_pred_baseline, average='macro'),\n",
        "    'precision_micro': precision_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "    'recall_micro': recall_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "    'hamming_loss': hamming_loss(y_test, y_pred_baseline),\n",
        "    'jaccard_score': jaccard_score(y_test, y_pred_baseline, average='micro', zero_division=0),\n",
        "}\n",
        "\n",
        "for metric, value in baseline_metrics.items():\n",
        "    print(f\"  {metric:20s}: {value:.4f} ({value*100:.2f}%)\")\n",
        "\n",
        "baseline_metrics['model'] = 'LinearSVC_Baseline'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8935d897",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "VOTINGCLASSIFIER ENSEMBLE MODEL METRICS\n",
            "======================================================================\n",
            "  f1_micro            : 0.5334 (53.34%)\n",
            "  f1_macro            : 0.4801 (48.01%)\n",
            "  precision_micro     : 0.7294 (72.94%)\n",
            "  recall_micro        : 0.4204 (42.04%)\n",
            "  hamming_loss        : 0.1336 (13.36%)\n",
            "  jaccard_score       : 0.3637 (36.37%)\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Ensemble Model\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"VOTINGCLASSIFIER ENSEMBLE MODEL METRICS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "ensemble_metrics = {\n",
        "    'f1_micro': f1_score(y_test, y_pred_ensemble, average='micro'),\n",
        "    'f1_macro': f1_score(y_test, y_pred_ensemble, average='macro'),\n",
        "    'precision_micro': precision_score(y_test, y_pred_ensemble, average='micro', zero_division=0),\n",
        "    'recall_micro': recall_score(y_test, y_pred_ensemble, average='micro', zero_division=0),\n",
        "    'hamming_loss': hamming_loss(y_test, y_pred_ensemble),\n",
        "    'jaccard_score': jaccard_score(y_test, y_pred_ensemble, average='micro', zero_division=0),\n",
        "}\n",
        "\n",
        "for metric, value in ensemble_metrics.items():\n",
        "    print(f\"  {metric:20s}: {value:.4f} ({value*100:.2f}%)\")\n",
        "\n",
        "ensemble_metrics['model'] = 'VotingClassifier_Ensemble'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "b6ca3016",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "MODEL COMPARISON\n",
            "======================================================================\n",
            "                   Baseline (LinearSVC)  Ensemble (VotingClassifier)  \\\n",
            "F1 (Micro)                       0.5519                       0.5334   \n",
            "F1 (Macro)                       0.5376                       0.4801   \n",
            "Precision (Micro)                0.6764                       0.7294   \n",
            "Recall (Micro)                   0.4661                       0.4204   \n",
            "Hamming Loss                     0.1375                       0.1336   \n",
            "Jaccard Score                    0.3811                       0.3637   \n",
            "\n",
            "                   Improvement  \n",
            "F1 (Micro)             -0.0185  \n",
            "F1 (Macro)             -0.0575  \n",
            "Precision (Micro)       0.0530  \n",
            "Recall (Micro)         -0.0456  \n",
            "Hamming Loss            0.0039  \n",
            "Jaccard Score          -0.0174  \n",
            "\n",
            "======================================================================\n",
            "SUMMARY\n",
            "======================================================================\n",
            "F1 (Micro) Improvement: -1.85 percentage points\n",
            "F1 (Macro) Improvement: -5.75 percentage points\n",
            "Precision Improvement: +5.30 percentage points\n",
            "Recall Improvement: -4.56 percentage points\n",
            "\n",
            "⚠ VotingClassifier does not improve over baseline\n"
          ]
        }
      ],
      "source": [
        "# Compare Models\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Baseline (LinearSVC)': [baseline_metrics[k] for k in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss', 'jaccard_score']],\n",
        "    'Ensemble (VotingClassifier)': [ensemble_metrics[k] for k in ['f1_micro', 'f1_macro', 'precision_micro', 'recall_micro', 'hamming_loss', 'jaccard_score']],\n",
        "}, index=['F1 (Micro)', 'F1 (Macro)', 'Precision (Micro)', 'Recall (Micro)', 'Hamming Loss', 'Jaccard Score'])\n",
        "\n",
        "# Calculate improvement\n",
        "comparison_df['Improvement'] = comparison_df['Ensemble (VotingClassifier)'] - comparison_df['Baseline (LinearSVC)']\n",
        "# For hamming_loss, lower is better, so flip the sign\n",
        "comparison_df.loc['Hamming Loss', 'Improvement'] = -comparison_df.loc['Hamming Loss', 'Improvement']\n",
        "\n",
        "print(comparison_df.round(4))\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"F1 (Micro) Improvement: {comparison_df.loc['F1 (Micro)', 'Improvement']*100:+.2f} percentage points\")\n",
        "print(f\"F1 (Macro) Improvement: {comparison_df.loc['F1 (Macro)', 'Improvement']*100:+.2f} percentage points\")\n",
        "print(f\"Precision Improvement: {comparison_df.loc['Precision (Micro)', 'Improvement']*100:+.2f} percentage points\")\n",
        "print(f\"Recall Improvement: {comparison_df.loc['Recall (Micro)', 'Improvement']*100:+.2f} percentage points\")\n",
        "\n",
        "if comparison_df.loc['F1 (Micro)', 'Improvement'] > 0:\n",
        "    print(\"\\n✓ VotingClassifier shows improvement!\")\n",
        "else:\n",
        "    print(\"\\n⚠ VotingClassifier does not improve over baseline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c48651bb",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "sparse array length is ambiguous; use getnnz() or shape[0]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Save results to JSON\u001b[39;00m\n\u001b[32m      2\u001b[39m results = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbaseline_metrics\u001b[39m\u001b[33m'\u001b[39m: baseline_metrics,\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mensemble_metrics\u001b[39m\u001b[33m'\u001b[39m: ensemble_metrics,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcomparison\u001b[39m\u001b[33m'\u001b[39m: comparison_df.to_dict(),\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mconfiguration\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m      7\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmodel_params\u001b[39m\u001b[33m'\u001b[39m: MODEL_PARAMS,\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m'\u001b[39m: THRESHOLD,\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mk_features\u001b[39m\u001b[33m'\u001b[39m: K_FEATURES,\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtrain_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train_final\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtest_samples\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(X_test_final),\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mnum_genres\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(mlb.classes_),\n\u001b[32m     13\u001b[39m     }\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m output_path = MODELS_DIR / \u001b[33m\"\u001b[39m\u001b[33mmetrics_votingclassifier.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/movie_genre_model/lib/python3.12/site-packages/scipy/sparse/_base.py:449\u001b[39m, in \u001b[36m_spbase.__len__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msparse array length is ambiguous; use getnnz()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    450\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33m or shape[0]\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mTypeError\u001b[39m: sparse array length is ambiguous; use getnnz() or shape[0]"
          ]
        }
      ],
      "source": [
        "# Save results to JSON\n",
        "results = {\n",
        "    'baseline_metrics': baseline_metrics,\n",
        "    'ensemble_metrics': ensemble_metrics,\n",
        "    'comparison': comparison_df.to_dict(),\n",
        "    'configuration': {\n",
        "        'model_params': MODEL_PARAMS,\n",
        "        'threshold': THRESHOLD,\n",
        "        'k_features': K_FEATURES,\n",
        "        'train_samples': len(X_train_final),\n",
        "        'test_samples': len(X_test_final),\n",
        "        'num_genres': len(mlb.classes_),\n",
        "    }\n",
        "}\n",
        "\n",
        "output_path = MODELS_DIR / \"metrics_votingclassifier.json\"\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "print(f\"\\n✓ Results saved to {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "movie_genre_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
