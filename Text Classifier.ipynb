{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f6344c-4fcb-441d-9441-e1b2f05be4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from torchmetrics.classification import MultilabelPrecision, MultilabelRecall, MultilabelF1Score, MultilabelExactMatch, MultilabelHammingDistance\n",
    "from typing import Dict, Any, Tuple, Optional\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beb4909-8c71-4dc1-82f4-15d43b17c03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_name     0\n",
       "genre          3\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "movies_df = pd.read_csv('top_movies.csv')\n",
    "movies_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec933c83-a14f-4c98-9940-a24c694fe428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_name     0\n",
       "genre          0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = movies_df.dropna()\n",
    "movies_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c83de8-4013-41ec-97ca-8fe8c628ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total empty sequences found: 0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "empty_sequences = []\n",
    "\n",
    "for idx, description in enumerate(movies_df['description'].tolist()):\n",
    "    encoding = tokenizer(\n",
    "        description,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "    if attention_mask.sum().item() == 0:\n",
    "        print(f\"⚠️ Empty sequence found at index {idx}: {description}\")\n",
    "        empty_sequences.append(idx)\n",
    "\n",
    "print(f\"\\n✅ Total empty sequences found: {len(empty_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d01ff7-8a19-482d-9204-c6a39aff0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre to index mapping: {'Action': 0, 'Adventure': 1, 'Animation': 2, 'Comedy': 3, 'Crime': 4, 'Drama': 5, 'Family': 6, 'Fantasy': 7, 'History': 8, 'Horror': 9, 'Music': 10, 'Mystery': 11, 'Romance': 12, 'Science Fiction': 13, 'TV Movie': 14, 'Thriller': 15, 'War': 16, 'Western': 17}\n"
     ]
    }
   ],
   "source": [
    "all_genres = set()\n",
    "for genres in movies_df['genre']:\n",
    "    for genre in genres.split(','):\n",
    "        all_genres.add(genre.strip())\n",
    "        \n",
    "genre_to_index = {genre: idx for idx, genre in enumerate(sorted(all_genres))}\n",
    "\n",
    "print(\"Genre to index mapping:\", genre_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c54bea-4399-4631-a1e8-8cfae2205329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDescriptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, genre_to_index: Dict[str, int], max_length: int = 128):\n",
    "        self.descriptions = dataframe['description'].tolist()\n",
    "        self.genres = dataframe['genre'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.genre_to_index = genre_to_index\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.descriptions)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        description = self.descriptions[idx]\n",
    "        genre_string = self.genres[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            description,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        label = torch.zeros(len(self.genre_to_index))\n",
    "        for genre in genre_string.split(','):\n",
    "            genre = genre.strip()\n",
    "            if genre in self.genre_to_index:\n",
    "                label[self.genre_to_index[genre]] = 1\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4ad6f8-47ff-4076-9972-d23b7c18211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(movies_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1780ee0-d3e3-4586-9831-d5a922fea4c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7533\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MovieDescriptionDataset(train_df, tokenizer, genre_to_index, max_length=128)\n",
    "val_dataset = MovieDescriptionDataset(val_df, tokenizer, genre_to_index, max_length=128)\n",
    "\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa194d91-38f1-440d-8c2f-01badb05c850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: tensor([  101,  1999,  1996,  3865,  1010,  1037,  7101,  2003,  4704,  2011,\n",
      "         2010,  2316,  2074,  2077,  2027,  2468,  2600, 18795,  2015,  1012,\n",
      "         3174,  2086,  2101,  1010,  1996,  7101,  5927,  2010,  2117,  3382,\n",
      "         2012,  2732,  9527, 13368,  2043,  2002,  2003,  2356,  2000,  4685,\n",
      "         2007,  2010,  9454,  7833,  1005,  1055,  2152,  2082,  2600,  2316,\n",
      "         1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Attention Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Labels: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "sample = train_dataset[0]\n",
    "\n",
    "print(\"Input IDs:\", sample['input_ids'])\n",
    "print(\"Attention Mask:\", sample['attention_mask'])\n",
    "print(\"Labels:\", sample['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7157935-0720-48a6-bf53-02e36dcc0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4a662a-5d9f-4088-b0f3-8c55247d35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionPooling(nn.Module):\n",
    "    \"\"\"\n",
    "    Self-Attention Pooling Layer with mask support.\n",
    "\n",
    "    This layer computes a learned attention weight for each token in the sequence\n",
    "    and returns a weighted sum of the sequence embeddings. Padded tokens are masked out\n",
    "    so they do not influence the pooled representation.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimensionality of the input embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model: int):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(d_model, d_model)\n",
    "        self.lin2 = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass for self-attention pooling.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, seq_len, d_model).\n",
    "            attn_mask (torch.Tensor): Boolean or binary tensor of shape (batch_size, seq_len),\n",
    "                where True/1 indicates valid tokens and False/0 indicates padding.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Pooled representation of shape (batch_size, d_model).\n",
    "        \"\"\"\n",
    "        m = attn_mask.bool()\n",
    "        scores = self.lin2(torch.tanh(self.lin1(x))).squeeze(-1)  # (B, T)\n",
    "        scores = scores.masked_fill(~m, float('-inf'))            # mask padding tokens\n",
    "        weights = torch.softmax(scores, dim=1).unsqueeze(-1)      # (B, T, 1)\n",
    "        return (weights * x).sum(dim=1)                           # (B, D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04215d10-2088-4926-9c25-9753003d9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighwayLayer(nn.Module):\n",
    "    def __init__(self, size: int) -> None:\n",
    "        super().__init__()\n",
    "        self.H: nn.Linear = nn.Linear(size, size)\n",
    "        self.T: nn.Linear = nn.Linear(size, size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        H_out = F.relu(self.H(x))\n",
    "        T_out = torch.sigmoid(self.T(x))\n",
    "        return H_out * T_out + x * (1 - T_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29bac456-25a4-4923-96d6-c74e92166668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based multi-label text classifier with:\n",
    "      - Transformer encoder backbone\n",
    "      - Masked self-attention pooling\n",
    "      - MLP trunk with residual connection and LayerNorm\n",
    "      - Label embedding classifier with normalized logits,\n",
    "        learnable temperature scaling, and bias\n",
    "      - Optional Monte Carlo dropout for uncertainty estimation and ensembling\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary.\n",
    "        emb_dim (int): Dimensionality of token embeddings.\n",
    "        hidden_dim (int): Hidden layer size in the classifier trunk.\n",
    "        num_classes (int): Number of target classes.\n",
    "        num_heads (int, optional): Number of attention heads in Transformer layers. Default is 8.\n",
    "        max_seq_length (int, optional): Maximum input sequence length. Default is 512.\n",
    "        num_attention_layers (int, optional): Number of Transformer encoder layers. Default is 4.\n",
    "        feedforward_dim (int, optional): Feedforward layer size inside Transformer. Default is 256.\n",
    "        num_dropout_samples (int, optional): Number of dropout samples for MC-dropout. Default is 8.\n",
    "        mc_dropout_enabled (bool, optional): Whether to enable MC-dropout averaging. Default is True.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "        num_heads: int = 8,\n",
    "        max_seq_length: int = 512,\n",
    "        num_attention_layers: int = 4,\n",
    "        feedforward_dim: int = 256,\n",
    "        num_dropout_samples: int = 8,\n",
    "        mc_dropout_enabled: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_dropout_samples = num_dropout_samples\n",
    "        self.mc_dropout_enabled = mc_dropout_enabled\n",
    "\n",
    "        # Embedding layers\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        nn.init.normal_(self.emb.weight, std=0.02)\n",
    "\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, max_seq_length, emb_dim))\n",
    "        nn.init.normal_(self.positional_encoding, std=0.02)\n",
    "        self.input_drop = nn.Dropout(0.3)\n",
    "\n",
    "        # Transformer encoder\n",
    "        transformer_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=feedforward_dim,\n",
    "            dropout=0.3,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            transformer_layer,\n",
    "            num_layers=num_attention_layers\n",
    "        )\n",
    "\n",
    "        # Attention pooling\n",
    "        self.attention_pooling = SelfAttentionPooling(emb_dim)\n",
    "\n",
    "        # Classifier trunk\n",
    "        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim // 2)\n",
    "        self.res_proj = nn.Identity() if (hidden_dim // 2) == emb_dim else nn.Linear(emb_dim, hidden_dim // 2)\n",
    "        self.layernorm_final = nn.LayerNorm(hidden_dim // 2)\n",
    "        self.text_to_label_space = nn.Linear(hidden_dim // 2, emb_dim)\n",
    "\n",
    "        # Label embeddings & logit head\n",
    "        self.label_embeddings = nn.Embedding(num_classes, emb_dim)\n",
    "        nn.init.normal_(self.label_embeddings.weight, std=0.02)\n",
    "        self.logit_bias = nn.Parameter(torch.zeros(num_classes))\n",
    "        self.logit_scale = nn.Parameter(torch.tensor(10.0))  # learnable temperature\n",
    "\n",
    "        # Dropout for MC-dropout averaging\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def enable_mc_dropout(self, enabled: bool = True) -> None:\n",
    "        \"\"\"\n",
    "        Enable or disable Monte Carlo dropout during evaluation.\n",
    "\n",
    "        Args:\n",
    "            enabled (bool): If True, keeps dropout layers active at eval-time\n",
    "                for stochastic forward passes. If False, disables dropout at eval-time.\n",
    "        \"\"\"\n",
    "        self.mc_dropout_enabled = enabled\n",
    "        if enabled:\n",
    "            self.dropout.train()\n",
    "        else:\n",
    "            self.dropout.eval()\n",
    "\n",
    "    def _encode(self, x: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Encode input token IDs using the Transformer encoder and attention pooling.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of token IDs, shape (batch_size, seq_len).\n",
    "            attention_mask (torch.Tensor): Attention mask of shape (batch_size, seq_len),\n",
    "                where True/1 indicates valid tokens and False/0 indicates padding.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Pooled sequence representation of shape (batch_size, emb_dim).\n",
    "        \"\"\"\n",
    "        mask_bool = attention_mask.bool()\n",
    "        x = self.emb(x) * math.sqrt(self.emb.embedding_dim)\n",
    "        x = x + self.positional_encoding[:, :x.size(1), :]\n",
    "        x = self.input_drop(x)\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=~mask_bool)\n",
    "        x = self.attention_pooling(x, mask_bool)\n",
    "        return x\n",
    "\n",
    "    def _trunk(self, pooled: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Pass pooled representation through the MLP trunk with residual connection.\n",
    "\n",
    "        Args:\n",
    "            pooled (torch.Tensor): Pooled sequence representation, shape (batch_size, emb_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Projected representation in label embedding space, shape (batch_size, emb_dim).\n",
    "        \"\"\"\n",
    "        residual = pooled\n",
    "        x = F.relu(self.fc1(pooled))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        residual = self.res_proj(residual)\n",
    "        x = self.layernorm_final(x + residual)\n",
    "        x_proj = self.text_to_label_space(x)\n",
    "        return x_proj\n",
    "\n",
    "    def _logits_from_proj(self, x_proj: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute class logits from projected representation using normalized dot product,\n",
    "        learnable temperature scaling, and bias.\n",
    "\n",
    "        Args:\n",
    "            x_proj (torch.Tensor): Projected representation, shape (batch_size, emb_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Class logits, shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        label_w = F.normalize(self.label_embeddings.weight, dim=-1)\n",
    "        text_z  = F.normalize(x_proj, dim=-1)\n",
    "        logits  = self.logit_scale * (text_z @ label_w.T) + self.logit_bias\n",
    "        return logits\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        debugging: bool = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the classifier.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input token IDs, shape (batch_size, seq_len).\n",
    "            attention_mask (torch.Tensor): Attention mask, shape (batch_size, seq_len).\n",
    "            debugging (bool, optional): If True, prints intermediate shapes for debugging.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Class logits, shape (batch_size, num_classes).\n",
    "        \"\"\"\n",
    "        if debugging:\n",
    "            print(f\"input_ids: {x.shape}, attention_mask: {attention_mask.shape}\")\n",
    "\n",
    "        pooled = self._encode(x, attention_mask)\n",
    "        if debugging:\n",
    "            print(f\"after encoder+pool: {pooled.shape}\")\n",
    "\n",
    "        x_proj = self._trunk(pooled)\n",
    "        if debugging:\n",
    "            print(f\"after trunk projection: {x_proj.shape}\")\n",
    "\n",
    "        use_mc = self.mc_dropout_enabled and (self.training or self.dropout.training)\n",
    "        if use_mc and self.num_dropout_samples > 1:\n",
    "            logits_list = []\n",
    "            for _ in range(self.num_dropout_samples):\n",
    "                dropped = self.dropout(x_proj)\n",
    "                logits_list.append(self._logits_from_proj(dropped))\n",
    "            logits = torch.stack(logits_list, dim=0).mean(dim=0)\n",
    "        else:\n",
    "            logits = self._logits_from_proj(x_proj)\n",
    "\n",
    "        if debugging:\n",
    "            print(f\"logits: {logits.shape}\")\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20e6c8f6-312c-473b-b0ac-33bf025996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma: float = 2.0, pos_weight: Optional[torch.Tensor] = None, reduction: str = 'mean') -> None:\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.pos_weight = pos_weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, pos_weight=self.pos_weight, reduction='none')\n",
    "        \n",
    "        probs = torch.sigmoid(logits)\n",
    "        probs = torch.clamp(probs, min=1e-6, max=1 - 1e-6)\n",
    "\n",
    "        focal_weight = torch.where(targets == 1, 1 - probs, probs) ** self.gamma\n",
    "        loss = focal_weight * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc9bfbd9-81bb-47b6-bacb-74b8c27acff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "119d977a-a1cf-4371-8b0e-d3191eb21f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30522\n",
    "emb_dim = 64\n",
    "hidden_dim = 128\n",
    "num_heads = 4\n",
    "\n",
    "num_classes = train_dataloader.dataset[0]['labels'].shape[-1]\n",
    "max_seq_length = 512\n",
    "num_attention_layers = 2\n",
    "feedforward_dim = 128\n",
    "num_dropout_samples = 5\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9455f1cc-7443-4375-bc6d-fdd0c9e6f3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    emb_dim=emb_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_heads=num_heads,\n",
    "    max_seq_length=max_seq_length,\n",
    "    num_attention_layers=num_attention_layers,\n",
    "    feedforward_dim=feedforward_dim,\n",
    "    num_dropout_samples=num_dropout_samples,\n",
    "    mc_dropout_enabled=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d5d623c-33db-4654-afd0-5c3b1526502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss() # FocalLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c8b30e3-d54f-417d-b529-36a6302961b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_metric = MultilabelHammingDistance(num_labels=num_classes)\n",
    "precision_metric = MultilabelPrecision(num_labels=num_classes, average='micro')\n",
    "recall_metric = MultilabelRecall(num_labels=num_classes, average='micro')\n",
    "f1_metric = MultilabelF1Score(num_labels=num_classes, average='micro')\n",
    "exact_match_metric = MultilabelExactMatch(num_labels=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b771bdc-c06d-4b20-85b5-021fea3dcde1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tune_per_label_thresholds(probs: np.ndarray, labels: np.ndarray, thresholds=np.linspace(0.0, 1.0, 101)):\n",
    "    \"\"\"\n",
    "    Tune per-label thresholds for multi-label classification.\n",
    "\n",
    "    This function iterates over a range of possible thresholds (default 0.0 to 1.0 in 0.01 steps)\n",
    "    for each class independently and chooses the threshold that maximizes the F1 score on the\n",
    "    validation dataset.\n",
    "\n",
    "    Args:\n",
    "        probs (np.ndarray): Predicted probabilities of shape (num_samples, num_classes).\n",
    "        labels (np.ndarray): Ground truth binary labels of shape (num_samples, num_classes).\n",
    "        thresholds (np.ndarray, optional): List of thresholds to evaluate for each label.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of best threshold values per label (shape: num_classes).\n",
    "    \"\"\"\n",
    "    num_classes = labels.shape[1]\n",
    "    best_thresholds = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        best_f1 = 0.0\n",
    "        best_thresh = 0.5\n",
    "        for thresh in thresholds:\n",
    "            preds = (probs[:, i] >= thresh).astype(int)\n",
    "            f1 = f1_score(labels[:, i], preds, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_thresh = thresh\n",
    "        best_thresholds[i] = best_thresh\n",
    "    return best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "912c1cf1-3592-4b03-8bdd-aee56581f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_label_smoothing(targets: torch.Tensor, smoothing: float = 0.1):\n",
    "    \"\"\"\n",
    "    Applies label smoothing to multi-label binary targets.\n",
    "\n",
    "    Args:\n",
    "        targets (torch.Tensor): Target tensor of shape (batch_size, num_classes), with 0/1 labels.\n",
    "        smoothing (float): Smoothing factor (e.g., 0.1).\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Smoothed targets.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        smoothed = targets * (1.0 - smoothing) + (1.0 - targets) * smoothing\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad49ac68-0e5a-4deb-912e-b347b6843eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    num_epochs: int,\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_classes: int,\n",
    "    patience: int = 2,\n",
    "    save_path: str = \"best_model.pt\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a multi-label classifier with per-label threshold tuning, early stopping, and detailed metrics.\n",
    "\n",
    "    Args:\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        model (torch.nn.Module): The PyTorch model to train.\n",
    "        train_dataloader (DataLoader): DataLoader for the training data.\n",
    "        val_dataloader (DataLoader): DataLoader for the validation data.\n",
    "        criterion (Loss): Loss function (e.g., FocalLoss or BCEWithLogitsLoss).\n",
    "        optimizer (Optimizer): Optimizer for updating model parameters.\n",
    "        device (torch.device): The device to run the training on.\n",
    "        num_classes (int): Number of output classes.\n",
    "        patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "        save_path (str): File path to save the best model.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Best per-class thresholds computed on the validation set.\n",
    "    \"\"\"\n",
    "\n",
    "    # Metrics\n",
    "    hamming_metric = MultilabelHammingDistance(num_labels=num_classes)\n",
    "    precision_metric = MultilabelPrecision(num_labels=num_classes, average='micro')\n",
    "    recall_metric = MultilabelRecall(num_labels=num_classes, average='micro')\n",
    "    f1_metric = MultilabelF1Score(num_labels=num_classes, average='micro')\n",
    "    exact_match_metric = MultilabelExactMatch(num_labels=num_classes)\n",
    "\n",
    "    best_thresholds = None\n",
    "    best_val_f1 = 0.0\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        all_train_labels = []\n",
    "        all_train_preds = []\n",
    "\n",
    "        loop = tqdm(train_dataloader, leave=True)\n",
    "        for batch in loop:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device).float()\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            smoothed_labels = apply_label_smoothing(labels, smoothing=0.1)\n",
    "            loss = criterion(outputs, smoothed_labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "            probs = torch.sigmoid(outputs).detach().cpu()\n",
    "            preds = (probs >= 0.4).int()\n",
    "\n",
    "            all_train_labels.append(labels.cpu().int())\n",
    "            all_train_preds.append(preds)\n",
    "\n",
    "        all_train_preds_tensor = torch.cat(all_train_preds)\n",
    "        all_train_labels_tensor = torch.cat(all_train_labels)\n",
    "\n",
    "        train_hamming_acc = 1.0 - hamming_metric(all_train_preds_tensor, all_train_labels_tensor)\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        train_precision = precision_metric(all_train_preds_tensor, all_train_labels_tensor)\n",
    "        train_recall = recall_metric(all_train_preds_tensor, all_train_labels_tensor)\n",
    "        train_f1 = f1_metric(all_train_preds_tensor, all_train_labels_tensor)\n",
    "        train_subset_acc = exact_match_metric(all_train_preds_tensor, all_train_labels_tensor)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_val_labels = []\n",
    "        all_val_probs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_dataloader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device).float()\n",
    "\n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                probs = torch.sigmoid(outputs).cpu()\n",
    "                all_val_probs.append(probs)\n",
    "                all_val_labels.append(labels.cpu().int())\n",
    "\n",
    "        val_probs_tensor = torch.cat(all_val_probs)\n",
    "        val_labels_tensor = torch.cat(all_val_labels)\n",
    "\n",
    "        val_probs_np = val_probs_tensor.numpy()\n",
    "        val_labels_np = val_labels_tensor.numpy()\n",
    "\n",
    "        # Threshold tuning\n",
    "        best_thresholds = tune_per_label_thresholds(val_probs_np, val_labels_np)\n",
    "        val_preds_np = (val_probs_np >= best_thresholds).astype(int)\n",
    "\n",
    "        val_hamming_acc = 1.0 - hamming_metric(torch.tensor(val_preds_np), val_labels_tensor)\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        val_precision = precision_score(val_labels_np, val_preds_np, average='micro', zero_division=0)\n",
    "        val_recall = recall_score(val_labels_np, val_preds_np, average='micro', zero_division=0)\n",
    "        val_f1 = f1_score(val_labels_np, val_preds_np, average='micro', zero_division=0)\n",
    "        val_subset_acc = (val_preds_np == val_labels_np).all(axis=1).mean()\n",
    "\n",
    "        print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Train Precision: {train_precision:.4f} | Val Precision: {val_precision:.4f}\")\n",
    "        print(f\"Train Recall:    {train_recall:.4f}    | Val Recall:    {val_recall:.4f}\")\n",
    "        print(f\"Train F1 Score:  {train_f1:.4f}        | Val F1 Score:  {val_f1:.4f}\")\n",
    "        print(f\"Train Subset Acc: {train_subset_acc:.4f} | Val Subset Acc: {val_subset_acc:.4f}\")\n",
    "        print(f\"Train Hamming Acc: {train_hamming_acc:.4f} | Val Hamming Acc: {val_hamming_acc:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            epochs_no_improve = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_thresholds': best_thresholds,\n",
    "            }, save_path)\n",
    "            print(\"📦 Model saved.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(\"🛑 Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(f\"Best Validation F1: {best_val_f1:.4f}\")\n",
    "    return best_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c653ca94-9c17-4ed1-9f08-25883cf436c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|███████████████| 942/942 [01:02<00:00, 15.16it/s, loss=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "Train Loss: 0.5209 | Val Loss: 0.3446\n",
      "Train Precision: 0.4198 | Val Precision: 0.2390\n",
      "Train Recall:    0.2170    | Val Recall:    0.6980\n",
      "Train F1 Score:  0.2861        | Val F1 Score:  0.3561\n",
      "Train Subset Acc: 0.0366 | Val Subset Acc: 0.0016\n",
      "Train Hamming Acc: 0.8404 | Val Hamming Acc: 0.6281\n",
      "📦 Model saved.\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|███████████████| 942/942 [01:05<00:00, 14.42it/s, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "Train Loss: 0.4703 | Val Loss: 0.2948\n",
      "Train Precision: 0.5543 | Val Precision: 0.3843\n",
      "Train Recall:    0.4821    | Val Recall:    0.6656\n",
      "Train F1 Score:  0.5157        | Val F1 Score:  0.4873\n",
      "Train Subset Acc: 0.0767 | Val Subset Acc: 0.0212\n",
      "Train Hamming Acc: 0.8666 | Val Hamming Acc: 0.7936\n",
      "📦 Model saved.\n",
      "\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|███████████████| 942/942 [01:02<00:00, 14.96it/s, loss=0.456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "Train Loss: 0.4391 | Val Loss: 0.2906\n",
      "Train Precision: 0.6520 | Val Precision: 0.4054\n",
      "Train Recall:    0.6580    | Val Recall:    0.6502\n",
      "Train F1 Score:  0.6550        | Val F1 Score:  0.4994\n",
      "Train Subset Acc: 0.1507 | Val Subset Acc: 0.0313\n",
      "Train Hamming Acc: 0.8978 | Val Hamming Acc: 0.8079\n",
      "📦 Model saved.\n",
      "\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|███████████████| 942/942 [01:05<00:00, 14.48it/s, loss=0.439]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Summary:\n",
      "Train Loss: 0.4198 | Val Loss: 0.2958\n",
      "Train Precision: 0.7147 | Val Precision: 0.5193\n",
      "Train Recall:    0.7392    | Val Recall:    0.6562\n",
      "Train F1 Score:  0.7268        | Val F1 Score:  0.5798\n",
      "Train Subset Acc: 0.2343 | Val Subset Acc: 0.0897\n",
      "Train Hamming Acc: 0.9181 | Val Hamming Acc: 0.8598\n",
      "📦 Model saved.\n",
      "\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|███████████████| 942/942 [01:07<00:00, 13.99it/s, loss=0.397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Summary:\n",
      "Train Loss: 0.4061 | Val Loss: 0.3125\n",
      "Train Precision: 0.7621 | Val Precision: 0.4359\n",
      "Train Recall:    0.7909    | Val Recall:    0.6800\n",
      "Train F1 Score:  0.7762        | Val F1 Score:  0.5313\n",
      "Train Subset Acc: 0.3094 | Val Subset Acc: 0.0472\n",
      "Train Hamming Acc: 0.9328 | Val Hamming Acc: 0.8232\n",
      "\n",
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|███████████████| 942/942 [01:06<00:00, 14.15it/s, loss=0.427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Summary:\n",
      "Train Loss: 0.3950 | Val Loss: 0.3256\n",
      "Train Precision: 0.8035 | Val Precision: 0.5017\n",
      "Train Recall:    0.8306    | Val Recall:    0.6612\n",
      "Train F1 Score:  0.8169        | Val F1 Score:  0.5705\n",
      "Train Subset Acc: 0.3956 | Val Subset Acc: 0.0775\n",
      "Train Hamming Acc: 0.9451 | Val Hamming Acc: 0.8533\n",
      "\n",
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|███████████████| 942/942 [01:10<00:00, 13.42it/s, loss=0.414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Summary:\n",
      "Train Loss: 0.3850 | Val Loss: 0.3324\n",
      "Train Precision: 0.8406 | Val Precision: 0.5187\n",
      "Train Recall:    0.8630    | Val Recall:    0.6550\n",
      "Train F1 Score:  0.8517        | Val F1 Score:  0.5789\n",
      "Train Subset Acc: 0.4735 | Val Subset Acc: 0.0817\n",
      "Train Hamming Acc: 0.9557 | Val Hamming Acc: 0.8596\n",
      "🛑 Early stopping triggered.\n",
      "Best Validation F1: 0.5798\n"
     ]
    }
   ],
   "source": [
    "best_thresholds = train(\n",
    "    num_epochs=10,\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_classes=num_classes,\n",
    "    patience=3,  # You can adjust this\n",
    "    save_path=\"best_model.pt\"  # Optional: customize the path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7714fe-cab8-4687-b1b1-19ac9099ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genres(description, model, tokenizer, genre_to_index, threshold=0.5, device=None):\n",
    "    \"\"\"\n",
    "    Predict genres for a given text description using a multi-label classifier.\n",
    "\n",
    "    This function tokenizes the input description, passes it through the model,\n",
    "    applies a sigmoid activation to get class probabilities, then thresholds them\n",
    "    to determine predicted genres.\n",
    "\n",
    "    Args:\n",
    "        description (str): Input text to classify (e.g., plot summary or description).\n",
    "        model (torch.nn.Module): Trained PyTorch multi-label classification model.\n",
    "        tokenizer (PreTrainedTokenizer): Tokenizer compatible with the model (e.g., from HuggingFace).\n",
    "        genre_to_index (dict): Mapping from genre labels to integer indices.\n",
    "        threshold (float, optional): Threshold for turning probabilities into binary predictions. Default is 0.5.\n",
    "        device (str or torch.device, optional): Device to run the model on. Defaults to 'cuda' if available.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of predicted genre labels for the input description.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    index_to_genre = {v: k for k, v in genre_to_index.items()}\n",
    "\n",
    "    # Tokenize the input description\n",
    "    encoding = tokenizer(\n",
    "        description,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "    predicted_labels = (probs >= threshold).astype(int)\n",
    "    predicted_genres = [index_to_genre[i] for i, label in enumerate(predicted_labels[0]) if label == 1]\n",
    "\n",
    "    return predicted_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a58342d-ca61-490b-ab21-3183886fe403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = TextClassifier(\n",
    "    vocab_size=vocab_size,\n",
    "    emb_dim=emb_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_classes=num_classes,\n",
    "    num_heads=num_heads,\n",
    "    max_seq_length=max_seq_length,\n",
    "    num_attention_layers=num_attention_layers,\n",
    "    feedforward_dim=feedforward_dim,\n",
    "    num_dropout_samples=num_dropout_samples\n",
    ").to(device)\n",
    "\n",
    "model_test.load_state_dict(torch.load(\"movie_checkpoint.pth\"))\n",
    "model_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761fbbb-ff36-4a9d-b123-40c8057c7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = (\n",
    "    \"A relentless high-speed chase through shadowy, abandoned streets catapults the protagonist \"\n",
    "    \"into a nightmarish world where unspeakable horrors await at every turn. Pursued not only by \"\n",
    "    \"ruthless mercenaries but also by terrifying supernatural forces, each moment is a desperate \"\n",
    "    \"fight for survival. As the line between reality and nightmare blurs, the hero must navigate \"\n",
    "    \"crumbling buildings, escape grotesque monsters lurking in the darkness, and confront \"\n",
    "    \"blood-soaked secrets that threaten to consume them. The pulse-pounding action is matched \"\n",
    "    \"only by the creeping dread that no place is safe and no one can be trusted in this brutal \"\n",
    "    \"race against time and terror.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8740d4cd-9c0b-44c9-a13c-9422a0176420",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_genres(description, model_test, tokenizer, genre_to_index, device='cpu')\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fd2e4-de81-4506-867e-24a796ed4b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
