{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f6344c-4fcb-441d-9441-e1b2f05be4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from typing import Dict, Any, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beb4909-8c71-4dc1-82f4-15d43b17c03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_name     0\n",
       "genre          3\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "movies_df = pd.read_csv('top_movies.csv')\n",
    "movies_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec933c83-a14f-4c98-9940-a24c694fe428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_name     0\n",
       "genre          0\n",
       "description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = movies_df.dropna()\n",
    "movies_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d01ff7-8a19-482d-9204-c6a39aff0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre to index mapping: {'Action': 0, 'Adventure': 1, 'Animation': 2, 'Comedy': 3, 'Crime': 4, 'Drama': 5, 'Family': 6, 'Fantasy': 7, 'History': 8, 'Horror': 9, 'Music': 10, 'Mystery': 11, 'Romance': 12, 'Science Fiction': 13, 'TV Movie': 14, 'Thriller': 15, 'War': 16, 'Western': 17}\n"
     ]
    }
   ],
   "source": [
    "all_genres = set()\n",
    "for genres in movies_df['genre']:\n",
    "    for genre in genres.split(','):\n",
    "        all_genres.add(genre.strip())\n",
    "        \n",
    "genre_to_index = {genre: idx for idx, genre in enumerate(sorted(all_genres))}\n",
    "\n",
    "print(\"Genre to index mapping:\", genre_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c54bea-4399-4631-a1e8-8cfae2205329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDescriptionDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, genre_to_index: Dict[str, int], max_length: int = 128):\n",
    "        self.descriptions = dataframe['description'].tolist()\n",
    "        self.genres = dataframe['genre'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.genre_to_index = genre_to_index\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.descriptions)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        description = self.descriptions[idx]\n",
    "        genre_string = self.genres[idx]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            description,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        label = torch.zeros(len(self.genre_to_index))\n",
    "        for genre in genre_string.split(','):\n",
    "            genre = genre.strip()\n",
    "            if genre in self.genre_to_index:\n",
    "                label[self.genre_to_index[genre]] = 1\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4ad6f8-47ff-4076-9972-d23b7c18211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(movies_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1780ee0-d3e3-4586-9831-d5a922fea4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieDescriptionDataset(train_df, tokenizer, genre_to_index, max_length=128)\n",
    "val_dataset = MovieDescriptionDataset(val_df, tokenizer, genre_to_index, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7157935-0720-48a6-bf53-02e36dcc0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65239f0b-4b04-4258-b1ee-11f14424a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_dim: int, \n",
    "                 num_heads: int, \n",
    "                 feedforward_dim: int = 256, \n",
    "                 dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=emb_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.layernorm1 = nn.LayerNorm(emb_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(emb_dim, feedforward_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(feedforward_dim, emb_dim)\n",
    "        )\n",
    "        self.layernorm2 = nn.LayerNorm(emb_dim)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # Multi-head attention block\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.layernorm1(x + self.dropout1(attn_output))  # Residual + LayerNorm\n",
    "\n",
    "        # Feed-forward block\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.layernorm2(x + self.dropout2(ff_output))  # Residual + LayerNorm\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bac456-25a4-4923-96d6-c74e92166668",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "        num_heads: int = 4,\n",
    "        max_seq_length: int = 128,\n",
    "        num_attention_layers: int = 2,\n",
    "        feedforward_dim: int = 256\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        self.positional_encoding = nn.Parameter(torch.zeros(1, max_seq_length, emb_dim))\n",
    "\n",
    "        # Stack Transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(emb_dim, num_heads, feedforward_dim) for _ in range(num_attention_layers)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.fc1 = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.layernorm_final = nn.LayerNorm(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.emb(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layernorm_final(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc9bfbd9-81bb-47b6-bacb-74b8c27acff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119d977a-a1cf-4371-8b0e-d3191eb21f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 30522\n",
    "emb_dim = 128\n",
    "hidden_dim = 256\n",
    "\n",
    "num_classes = len(genre_to_index)\n",
    "max_seq_length = 128\n",
    "\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9455f1cc-7443-4375-bc6d-fdd0c9e6f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassifier(vocab_size, emb_dim, hidden_dim, num_classes, num_heads=8).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b771bdc-c06d-4b20-85b5-021fea3dcde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 471/471 [01:09<00:00,  6.82it/s, loss=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss: 0.3652\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████▍                | 203/471 [00:32<00:41,  6.48it/s, loss=0.365]"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch + 1}/{num_epochs}]\")\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average Training Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477846b-bb53-476c-b703-9db1a38a3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: torch.nn.Module, \n",
    "                   dataloader: DataLoader, \n",
    "                   threshold: float = 0.5, \n",
    "                   device: str = 'cpu') -> Tuple[float, float, float, float]:\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "            outputs = model(input_ids)\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "\n",
    "            preds = (probs >= threshold).astype(int)\n",
    "\n",
    "            all_labels.extend(labels)\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    # Compute multi-label metrics\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "    subset_acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "    print(f\"Validation Precision: {precision:.4f}\")\n",
    "    print(f\"Validation Recall: {recall:.4f}\")\n",
    "    print(f\"Validation Subset Accuracy: {subset_acc:.4f}\\n\")\n",
    "\n",
    "    return f1, precision, recall, subset_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a10a2-8062-4e0c-a8d6-aa875ee76e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, val_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7714fe-cab8-4687-b1b1-19ac9099ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genres(model, tokenizer, description, index_to_genre, threshold=0.7, max_length=128, device='cpu'):\n",
    "    model.eval()\n",
    "    genres = []\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        description,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        predicted_indices = (probs[0] >= threshold).nonzero(as_tuple=True)[0].tolist()\n",
    "        genres = [index_to_genre[idx] for idx in predicted_indices]\n",
    "\n",
    "    return genres\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
